<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Apache Spark: the New ‘king’ of Big Data - Gao Haojun</title><link rel="manifest" href="/Blog/manifest.json"><meta name="application-name" content="Gao Haojun"><meta name="msapplication-TileImage" content="/img/favicon.jpeg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Gao Haojun"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content=""><meta property="og:type" content="blog"><meta property="og:title" content="Apache Spark: the New ‘king’ of Big Data"><meta property="og:url" content="http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/"><meta property="og:site_name" content="Gao Haojun"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://logz.io/wp-content/uploads/2018/02/hadoop-vs-spark-article-1.jpg"><meta property="og:image" content="https://databricks.com/wp-content/uploads/2019/03/gloss-spark1.png"><meta property="og:image" content="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture5-2-768x408.png"><meta property="og:image" content="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/2018-09-28-18_12_51-Apache-Spark-Architecture-_-Understanding-the-Spark-Components-_-Edureka.png"><meta property="og:image" content="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture1-5-768x266.png"><meta property="og:image" content="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2018/02/Kafka-Hadoop-Spark-Architecture-1024x666.png"><meta property="og:image" content="https://spark.apache.org/docs/latest/img/ml-Pipeline.png"><meta property="og:image" content="https://spark.apache.org/docs/latest/img/ml-PipelineModel.png"><meta property="article:published_time" content="2020-12-09T12:22:32.000Z"><meta property="article:modified_time" content="2022-02-22T03:27:13.000Z"><meta property="article:author" content="Haojun(Vincent) Gao"><meta property="article:tag" content="Spark"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://logz.io/wp-content/uploads/2018/02/hadoop-vs-spark-article-1.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/"},"headline":"Apache Spark: the New ‘king’ of Big Data","image":["https://logz.io/wp-content/uploads/2018/02/hadoop-vs-spark-article-1.jpg","https://databricks.com/wp-content/uploads/2019/03/gloss-spark1.png","https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture5-2-768x408.png","https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/2018-09-28-18_12_51-Apache-Spark-Architecture-_-Understanding-the-Spark-Components-_-Edureka.png","https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture1-5-768x266.png","https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2018/02/Kafka-Hadoop-Spark-Architecture-1024x666.png","https://spark.apache.org/docs/latest/img/ml-Pipeline.png","https://spark.apache.org/docs/latest/img/ml-PipelineModel.png"],"datePublished":"2020-12-09T12:22:32.000Z","dateModified":"2022-02-22T03:27:13.000Z","author":{"@type":"Person","name":"Haojun(Vincent) Gao"},"publisher":{"@type":"Organization","name":"Gao Haojun","logo":{"@type":"ImageObject","url":"http://vincentgaohj.github.io/img/logo.jpg"}},"description":""}</script><link rel="canonical" href="http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/"><link rel="icon" href="/Blog/img/favicon.jpeg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.7.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/Blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?192470116504c325dfc73c99f66225ed";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-N6S845NT1J" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-N6S845NT1J');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 8.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/Blog/"><img src="/Blog/img/logo.jpg" alt="Gao Haojun" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/Blog/">Home</a><a class="navbar-item" href="/Blog/archives">Archives</a><a class="navbar-item" href="/Blog/categories">Categories</a><a class="navbar-item" href="/Blog/tags">Tags</a><a class="navbar-item" href="/Blog/about">About</a><a class="navbar-item" href="/Blog/links">Links</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/VincentGaoHJ"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-12-09T12:22:32.000Z" title="2020/12/9 20:22:32">2020-12-09</time></span><span class="level-item"><a class="link-muted" href="/Blog/categories/Big-Data/">Big Data</a><span> / </span><a class="link-muted" href="/Blog/categories/Big-Data/Spark/">Spark</a></span><span class="level-item">15 minutes read (About 2228 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Apache Spark: the New ‘king’ of Big Data</h1><div class="content"><p><img src="https://logz.io/wp-content/uploads/2018/02/hadoop-vs-spark-article-1.jpg"></p>
<span id="more"></span>

<p>[TOC]</p>
<h2 id="About"><a href="#About" class="headerlink" title="About"></a>About</h2><h3 id="What-is-Hadoop"><a href="#What-is-Hadoop" class="headerlink" title="What is Hadoop?"></a>What is Hadoop?</h3><p>It’s a general-purpose form of distributed processing that has several components: </p>
<ul>
<li><strong>HDFS</strong>(The Hadoop Distributed File System), which stores files in a Hadoop-native format and parallelizes them across a cluster; </li>
<li><strong>YARN</strong>, a schedule that coordinates application runtimes; </li>
<li><strong>MapReduce</strong>, the algorithm that actually processes the data in parallel.</li>
</ul>
<p>Hadoop is built in Java, and accessible through many programming languages, for writing MapReduce code, including Python, through a Thrift client.</p>
<h3 id="What-is-Apache-Spark"><a href="#What-is-Apache-Spark" class="headerlink" title="What is Apache Spark?"></a>What is Apache Spark?</h3><p>Spark as a whole consists of various libraries, APIs, databases, etc. The main components of Apache Spark are as follows:</p>
<ul>
<li><p>**Spark Core: **Spare Core is the basic building block of Spark, which includes all components for job scheduling, performing various memory operations, fault tolerance, and more. Spark Core is also home to the API that consists of RDD. Moreover, Spark Core provides APIs for building and manipulating data in RDD.</p>
</li>
<li><p>**Spark SQL: **Apache Spark works with the unstructured data using its ‘go to’ tool, Spark SQL. Spark SQL allows querying data via SQL, as well as via Apache Hive’s form of SQL called Hive Query Language (HQL). It also supports data from various sources like parse tables, log files, JSON, etc. Spark SQL allows programmers to combine SQL queries with <strong>programmable changes or manipulations</strong> supported by RDD in Python, Java, Scala, and R.</p>
</li>
<li><p>**Spark Streaming: **Spark Streaming processes live streams of data. Data generated by various sources is processed at the very instant by Spark Streaming. Examples of this data include log files, messages containing status updates posted by users, etc.</p>
</li>
<li><p>**GraphX: **GraphX is Apache Spark’s library for enhancing graphs and enabling graph-parallel computation. Apache Spark includes a number of graph algorithms which help users in simplifying graph analytics.</p>
</li>
<li><p>**MLlib: **Apache Spark comes up with a library containing common Machine Learning (ML) services called MLlib. It provides various types of ML algorithms including regression, clustering, and classification, which can perform various operations on data to get meaningful insights out of it.</p>
</li>
</ul>
<p><img src="https://databricks.com/wp-content/uploads/2019/03/gloss-spark1.png"></p>
<p>Spark has several APIs. The original interface was written in Scala, and based on heavy usage by data scientists, Python and R endpoints were also added. Java is another option for writing Spark jobs.  </p>
<h3 id="Apache-Spark-vs-Hadoop-vs-Hive"><a href="#Apache-Spark-vs-Hadoop-vs-Hive" class="headerlink" title="Apache Spark vs Hadoop vs Hive"></a>Apache Spark vs Hadoop vs Hive</h3><p>That’s not to say Hadoop is obsolete. It does things that Spark does not, and often provides the framework upon which Spark works. The <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">Hadoop Distributed File System</a> enables the service to store and index files, serving as a virtual data infrastructure.</p>
<p>Spark, on the other hand, performs distributed, high-speed compute functions on that architecture. <strong>If Hadoop is the professional kitchen with the tools and equipment to build and cook meals of data, then Spark is the expediter that rapidly assembles and distributes those meals for consumption.</strong></p>
<p>Because Spark was built to work with and run on the Hadoop infrastructure, the two systems work well together. Fast-growing organizations built in Hadoop can easily add Spark’s speed and functionality as needed.</p>
<p>As for the different between hive and Spark, they are different products built for different purposes in the big data space. <strong>Hive is a distributed database, and Spark is a framework for data analytics.</strong></p>
<p><strong>Hive</strong> is a pure data warehousing database which stores data in the form of tables. As a result, it can only process structured data read and written using SQL queries. Hive is not an option for unstructured data. In addition, Hive is not an ideal for OLTP or OLAP kinds of operations.</p>
<hr>
<h2 id="Key-Terminology-and-Concepts"><a href="#Key-Terminology-and-Concepts" class="headerlink" title="Key Terminology and Concepts"></a>Key Terminology and Concepts</h2><ul>
<li><strong>Spark RDDs</strong><ul>
<li><strong>Resilient Distributed Datasets are data structures that are the core building blocks of Spark.</strong> A RDD is an immutable, partitioned collection of records, which means that it can hold values, tuples, or other objects, these records are partitioned so as to be processed on a distributed system, and that once an RDD has been made, it is impossible to alter it.</li>
<li><strong>Spark DataFrame</strong> have all of the features of RDDs but also have a schema. This will make them our data structure of choice for getting started with PySpark.</li>
<li><strong>Spark DataSets</strong> are similar to DataFrames but are <em>strongly-typed,</em> meaning that the type is specified upon the creation of the DataSet and is not inferred from the type of records stored in it. <em>This means DataSets are not used in PySpark because Python is a dynamically-typed language.</em></li>
</ul>
</li>
<li><strong>Transformations</strong><ul>
<li>Transformations are one of the things you can do to an RDD in Spark.</li>
<li>Transformations take an RDD as an input and perform some function on them based on what Transformation is being called, and outputs one or more RDDs.</li>
</ul>
</li>
<li><strong>Actions</strong> <ul>
<li>An Action is any RDD operation that does not produce an RDD as an output. </li>
<li>Aan Action is the cue to the compiler to evaluate the lineage graph and return the value specified by the Action.</li>
</ul>
</li>
<li><strong>Lineage Graph</strong><ul>
<li>A lineage graph outlines what is called a “logical execution plan”. What that means is that the compiler begins with the earliest RDDs that aren’t dependent on any other RDDs, and follows a logical chain of Transformations until it ends with the RDD that an Action is called on. </li>
<li>This feature is primarily what drives Spark’s fault tolerance. If a node fails for some reason, all the information about what that node was supposed to be doing is stored in the lineage graph, which can be replicated elsewhere.</li>
</ul>
</li>
<li><strong>Application</strong><ul>
<li>A Spark <strong>application</strong> is a user built program that consists of a driver and that driver’s associated executors.</li>
</ul>
</li>
<li><strong>Job</strong><ul>
<li>A Spark <strong>job</strong> is task or set of tasks to be executed with executor processes, as directed by the driver. </li>
<li>A job is triggered by the calling of an RDD Action.</li>
</ul>
</li>
<li><strong>Map Stage</strong> in Map Reduce<ul>
<li>The map or mapper’s job is to process the input data. Generally the input data is in the form of file or directory and is stored in the Hadoop file system (HDFS). </li>
<li>The input file is passed to the mapper function line by line. The mapper processes the data and creates several small chunks of data.</li>
</ul>
</li>
<li><strong>Reduce Stage</strong> in Map Reduce<ul>
<li>This stage is the combination of the <strong>Shuffle</strong> stage and the <strong>Reduce</strong> stage. </li>
<li>The Reducer’s job is to process the data that comes from the mapper. After processing, it produces a new set of output, which will be stored in the HDFS.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="Apache-Spark-Architecture"><a href="#Apache-Spark-Architecture" class="headerlink" title="Apache Spark Architecture"></a>Apache Spark Architecture</h2><h3 id="Features-of-Apache-Spark"><a href="#Features-of-Apache-Spark" class="headerlink" title="Features of Apache Spark"></a>Features of Apache Spark</h3><p><img src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture5-2-768x408.png"></p>
<ul>
<li><strong>Speed</strong></li>
</ul>
<p>Spark runs up to 100 times faster than Hadoop MapReduce for large-scale data processing. It is also able to achieve this speed through controlled partitioning.</p>
<ul>
<li><p><strong>Powerful Caching</strong></p>
<p>Simple programming layer provides powerful caching and disk persistence capabilities.</p>
</li>
<li><p><strong>Deployment</strong></p>
<p>It can be deployed through <em><strong>Mesos, Hadoop via YARN, or Spark’s own cluster manager.</strong></em></p>
</li>
<li><p><strong>Real-Time</strong><br>It offers Real-time computation &amp; low latency because of <em><strong>in-memory computation.</strong></em></p>
</li>
<li><p><strong>Polyglot</strong></p>
</li>
</ul>
<p>  Spark provides high-level APIs in Java, Scala, Python, and R. Spark code can be written in any of these four languages. It also provides a shell in Scala and Python.</p>
<h3 id="Spark-Architecture-Overview"><a href="#Spark-Architecture-Overview" class="headerlink" title="Spark Architecture Overview"></a>Spark Architecture Overview</h3><p>Apache Spark has a well-defined layered architecture where all the spark components and layers are loosely coupled. This architecture is further integrated with various extensions and libraries. Apache Spark Architecture is based on two main abstractions:</p>
<ul>
<li><em>Resilient Distributed Dataset (RDD)</em></li>
<li><em>Directed Acyclic Graph (DAG)</em></li>
</ul>
<p><img src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/2018-09-28-18_12_51-Apache-Spark-Architecture-_-Understanding-the-Spark-Components-_-Edureka.png" alt="Spark Architecture"></p>
<h3 id="Resilient-Distributed-Dataset-RDD"><a href="#Resilient-Distributed-Dataset-RDD" class="headerlink" title="Resilient Distributed Dataset(RDD)"></a>Resilient Distributed Dataset(RDD)</h3><p>RDDs are the building blocks of any Spark application. RDDs Stands for:</p>
<ul>
<li><strong>Resilient:</strong> Fault tolerant and is capable of rebuilding data on failure</li>
<li><strong>Distributed:</strong> Distributed data among the multiple nodes in a cluster</li>
<li><strong>Dataset:</strong> Collection of partitioned data with values</li>
</ul>
<p><img src="https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2018/09/Picture1-5-768x266.png" alt="Workflow of RDD"></p>
<hr>
<h2 id="Using-Hadoop-and-Spark-together"><a href="#Using-Hadoop-and-Spark-together" class="headerlink" title="Using Hadoop and Spark together"></a>Using Hadoop and Spark together</h2><p>There are several instances where you would want to use the two tools together. Despite some asking if Spark will replace Hadoop entirely because of the former’s processing power, they are meant to complement each other rather than compete. Below you can see a simplified version of Spark-and-Hadoop architecture:</p>
<p><img src="https://dytvr9ot2sszz.cloudfront.net/wp-content/uploads/2018/02/Kafka-Hadoop-Spark-Architecture-1024x666.png" alt="Hadoop-Kafka-Spark Architecture Diagram: How Spark works together with Hadoop and Kafka"></p>
<p>Hadoop can—at a lower price—deal with heavier operations while Spark processes the more numerous smaller jobs that need instantaneous turnaround.</p>
<p>YARN also makes archiving and analysis of archived data possible, whereas it isn’t with Apache Spark. Thus, Hadoop and YARN in particular becomes a critical thread for tying together the real-time processing, machine learning and reiterated graph processing.</p>
<hr>
<h2 id="Summing-it-up"><a href="#Summing-it-up" class="headerlink" title="Summing it up"></a>Summing it up</h2><p><strong>So is it Hadoop or Spark?</strong> These systems are two of the most prominent distributed systems for processing data on the market today. Hadoop is used mainly for disk-heavy operations with the MapReduce paradigm, and Spark is a more flexible, but more costly in-memory processing architecture. Both are Apache top-level projects, are often used together, and have similarities, but it’s important to understand the features of each when deciding to implement them.</p>
<p><strong>So is it Spark or Hive?</strong> Hive and Spark are both immensely popular tools in the big data world. Hive is the best option for performing data analytics on large volumes of data using SQLs. Spark, on the other hand, is the best option for running big data analytics. It provides a faster, more modern alternative to MapReduce.</p>
<hr>
<h2 id="ML-Pipelines"><a href="#ML-Pipelines" class="headerlink" title="ML Pipelines"></a><strong>ML Pipelines</strong></h2><p>ML Pipelines provide a uniform set of high-level APIs built on top of <a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/sql-programming-guide.html">DataFrames</a> that help users create and tune practical machine learning pipelines.</p>
<ul>
<li><p><strong>Main concepts in Pipelines</strong></p>
<ul>
<li><strong><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html#dataframe"><code>DataFrame</code></a></strong>: This ML API uses <code>DataFrame</code> from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a <code>DataFrame</code> could have different columns storing text, feature vectors, true labels, and predictions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html#transformers"><code>Transformer</code></a></strong>: A <code>Transformer</code> is an algorithm which can transform one <code>DataFrame</code> into another <code>DataFrame</code>. E.g., an ML model is a <code>Transformer</code> which transforms a <code>DataFrame</code> with features into a <code>DataFrame</code> with predictions.</li>
<li><strong><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html#estimators"><code>Estimator</code></a></strong>: An <code>Estimator</code> is an algorithm which can be fit on a <code>DataFrame</code> to produce a <code>Transformer</code>. E.g., a learning algorithm is an <code>Estimator</code> which trains on a <code>DataFrame</code> and produces a model.</li>
<li><strong><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline"><code>Pipeline</code></a></strong>: A <code>Pipeline</code> chains multiple <code>Transformer</code>s and <code>Estimator</code>s together to specify an ML workflow.</li>
<li><strong><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html#parameters"><code>Parameter</code></a></strong>: All <code>Transformer</code>s and <code>Estimator</code>s now share a common API for specifying parameters.</li>
</ul>
</li>
<li><p><strong>How it works</strong></p>
<p><img src="https://spark.apache.org/docs/latest/img/ml-Pipeline.png" alt="ML Pipeline Example"></p>
<ul>
<li>The first two (<code>Tokenizer</code> and <code>HashingTF</code>) are <code>Transformer</code>s (blue), and the third (<code>LogisticRegression</code>) is an <code>Estimator</code> (red). The bottom row represents data flowing through the pipeline, where cylinders indicate <code>DataFrame</code>s. </li>
<li>The <code>Pipeline.fit()</code> method is called on the original <code>DataFrame</code>, which has raw text documents and labels. </li>
<li>The <code>Tokenizer.transform()</code> method splits the raw text documents into words, adding a new column with words to the <code>DataFrame</code>. </li>
<li>The <code>HashingTF.transform()</code> method converts the words column into feature vectors, adding a new column with those vectors to the <code>DataFrame</code>. </li>
<li>Now, since <code>LogisticRegression</code> is an <code>Estimator</code>, the <code>Pipeline</code> first calls <code>LogisticRegression.fit()</code> to produce a <code>LogisticRegressionModel</code>. </li>
<li>If the <code>Pipeline</code> had more <code>Estimator</code>s, it would call the <code>LogisticRegressionModel</code>’s <code>transform()</code> method on the <code>DataFrame</code> before passing the <code>DataFrame</code> to the next stage.</li>
</ul>
<p><img src="https://spark.apache.org/docs/latest/img/ml-PipelineModel.png" alt="ML PipelineModel Example"></p>
<ul>
<li>A <code>Pipeline</code> is an <code>Estimator</code>. Thus, after a <code>Pipeline</code>’s <code>fit()</code> method runs, it produces a <code>PipelineModel</code>, which is a <code>Transformer</code>. This <code>PipelineModel</code> is used at <em>test time</em>; the figure below illustrates this usage.</li>
<li>In the figure above, the <code>PipelineModel</code> has the same number of stages as the original <code>Pipeline</code>, but all <code>Estimator</code>s in the original <code>Pipeline</code> have become <code>Transformer</code>s. </li>
<li>When the <code>PipelineModel</code>’s <code>transform()</code> method is called on a test dataset, the data are passed through the fitted pipeline in order. </li>
<li>Each stage’s <code>transform()</code> method updates the dataset and passes it to the next stage.</li>
<li><code>Pipeline</code>s and <code>PipelineModel</code>s help to ensure that training and test data go through identical feature processing steps.</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427">A Neanderthal’s Guide to Apache Spark in Python</a></li>
<li><a target="_blank" rel="noopener" href="https://www.edureka.co/blog/spark-architecture/#Spark">Apache Spark Architecture – Spark Cluster Architecture Explained</a></li>
<li><a target="_blank" rel="noopener" href="https://logz.io/blog/hadoop-vs-spark/">How do Hadoop and Spark Stack Up?</a></li>
<li><a target="_blank" rel="noopener" href="https://spark.apache.org/docs/latest/ml-pipeline.html">MLlib: ML Pipelines</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Apache Spark: the New ‘king’ of Big Data</p><p><a href="http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/">http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Haojun(Vincent) Gao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-12-09</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-02-22</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-globe"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/Blog/tags/Spark/">Spark</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=62145317b846610019d3dc05&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/@vincent_gaohj" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>Afdian.net</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/Blog/img/alipay.jpg" alt="Alipay"></span></a><a class="button donate" href="https://www.buymeacoffee.com/gaohaojun" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Blog/2020/12/20/How-to-Make-the-Best-Pour-Over-Coffee-Like-a-Pro/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">How to Make the Best Pour Over Coffee Like a Pro</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Blog/2020/12/08/Docker-Django-React-AWS-Deploying-Containerized-Application-to-Cloud/"><span class="level-item">Docker, Django, React, AWS: Deploying Containerized Application to Cloud</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://vincentgaohj.github.io/Blog/2020/12/09/Apache-Spark-the-new-king-of-Big-Data/';
            this.page.identifier = '2020/12/09/Apache-Spark-the-new-king-of-Big-Data/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'vincentgaohj' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/Blog/2025/12/10/OpenRouter-%E7%9A%84-100-%E4%B8%87%E4%BA%BF-Tokens-%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6/"><img src="/Blog/gallery/OpenRouter-100-Tokens/tokens.png" alt="OpenRouter 的 100 万亿 Tokens 实证研究"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-12-10T03:37:07.000Z">2025-12-10</time></p><p class="title"><a href="/Blog/2025/12/10/OpenRouter-%E7%9A%84-100-%E4%B8%87%E4%BA%BF-Tokens-%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6/">OpenRouter 的 100 万亿 Tokens 实证研究</a></p><p class="categories"><a href="/Blog/categories/AI/">AI</a> / <a href="/Blog/categories/AI/Analytics/">Analytics</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2025/12/03/TPU%20%E4%B8%8E%20GPU%20%E7%9A%84%E6%9C%AA%E6%9D%A5%E7%AB%9E%E4%BA%89%E6%A0%BC%E5%B1%80%E6%80%81%E5%8A%BF/"><img src="/Blog/gallery/GPU-TPU/tpu-vs-gpu.png" alt="TPU 与 GPU 的未来竞争格局态势"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-12-03T03:38:07.000Z">2025-12-03</time></p><p class="title"><a href="/Blog/2025/12/03/TPU%20%E4%B8%8E%20GPU%20%E7%9A%84%E6%9C%AA%E6%9D%A5%E7%AB%9E%E4%BA%89%E6%A0%BC%E5%B1%80%E6%80%81%E5%8A%BF/">TPU 与 GPU 的未来竞争格局态势</a></p><p class="categories"><a href="/Blog/categories/AI/">AI</a> / <a href="/Blog/categories/AI/Analytics/">Analytics</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2025/10/14/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%B7%E6%A0%BC%E8%B6%8B%E5%8A%BF%E4%B8%8E%E5%AE%9A%E4%BB%B7%E8%89%BA%E6%9C%AF/"><img src="/Blog/gallery/Deploying-AWS-Lambda-with-Terraform/bailey_zindel.jpg" alt="大模型的价格趋势与定价艺术"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-10-14T02:32:09.000Z">2025-10-14</time></p><p class="title"><a href="/Blog/2025/10/14/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%B7%E6%A0%BC%E8%B6%8B%E5%8A%BF%E4%B8%8E%E5%AE%9A%E4%BB%B7%E8%89%BA%E6%9C%AF/">大模型的价格趋势与定价艺术</a></p><p class="categories"><a href="/Blog/categories/AI/">AI</a> / <a href="/Blog/categories/AI/Analytics/">Analytics</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2025/09/24/State-of-AI-2025/"><img src="/Blog/gallery/State-of-AI-2025/intelligence.png" alt="State of AI 2025"></a></figure><div class="media-content"><p class="date"><time dateTime="2025-09-24T03:38:07.000Z">2025-09-24</time></p><p class="title"><a href="/Blog/2025/09/24/State-of-AI-2025/">State of AI 2025</a></p><p class="categories"><a href="/Blog/categories/AI/">AI</a> / <a href="/Blog/categories/AI/Analytics/">Analytics</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2022/06/22/What-is-Knative-K-for-Kubernetes-Native/"><img src="/Blog/gallery/What-is-Knative-K-for-Kubernetes-Native/knative.png" alt="What is Knative?  K for Kubernetes + Native"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-06-22T02:22:34.000Z">2022-06-22</time></p><p class="title"><a href="/Blog/2022/06/22/What-is-Knative-K-for-Kubernetes-Native/">What is Knative?  K for Kubernetes + Native</a></p><p class="categories"><a href="/Blog/categories/Cloud-Native/">Cloud Native</a> / <a href="/Blog/categories/Cloud-Native/Kubernetes/">Kubernetes</a> / <a href="/Blog/categories/Cloud-Native/Kubernetes/Knative/">Knative</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/Blog/categories/AI/"><span class="level-start"><span class="level-item">AI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/AI/Analytics/"><span class="level-start"><span class="level-item">Analytics</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/AWS/"><span class="level-start"><span class="level-item">AWS</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/AWS/AWS-Certified-Machine-Learning-Specialty/"><span class="level-start"><span class="level-item">AWS Certified Machine Learning Specialty</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/AWS-Certified-Solution-Architect-Associate/"><span class="level-start"><span class="level-item">AWS Certified Solution Architect Associate</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/Serverless/"><span class="level-start"><span class="level-item">Serverless</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/NMF/"><span class="level-start"><span class="level-item">NMF</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Natural-Language-Processing/"><span class="level-start"><span class="level-item">Natural Language Processing</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Reinforce-Learning/"><span class="level-start"><span class="level-item">Reinforce Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Big-Data/"><span class="level-start"><span class="level-item">Big Data</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Big-Data/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Cloud-Native/"><span class="level-start"><span class="level-item">Cloud Native</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Cloud-Native/Kubernetes/"><span class="level-start"><span class="level-item">Kubernetes</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Cloud-Native/Kubernetes/Knative/"><span class="level-start"><span class="level-item">Knative</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Development/"><span class="level-start"><span class="level-item">Development</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Development/Android/"><span class="level-start"><span class="level-item">Android</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/Full-Stack/"><span class="level-start"><span class="level-item">Full Stack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/Log-Stack/"><span class="level-start"><span class="level-item">Log Stack</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/English-Study/"><span class="level-start"><span class="level-item">English Study</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Finance/"><span class="level-start"><span class="level-item">Finance</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Finance/Asset-Management/"><span class="level-start"><span class="level-item">Asset Management</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Finance/Econometrics/"><span class="level-start"><span class="level-item">Econometrics</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/LaTeX/"><span class="level-start"><span class="level-item">LaTeX</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Lifestyle/"><span class="level-start"><span class="level-item">Lifestyle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Terraform/"><span class="level-start"><span class="level-item">Terraform</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Terraform/Serverless/"><span class="level-start"><span class="level-item">Serverless</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/Blog/tags/AI/"><span class="tag">AI</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/AWS/"><span class="tag">AWS</span><span class="tag">19</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/AWS-Serverless/"><span class="tag">AWS - Serverless</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Android/"><span class="tag">Android</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Apps/"><span class="tag">Apps</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Certified/"><span class="tag">Certified</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Certified-Machine-Learning-Specialty/"><span class="tag">Certified Machine Learning - Specialty</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Cloud-Native-Kubernetes/"><span class="tag">Cloud Native - Kubernetes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Clustering/"><span class="tag">Clustering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Coffee/"><span class="tag">Coffee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Deep-Learning/"><span class="tag">Deep-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Django/"><span class="tag">Django</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/EKK/"><span class="tag">EKK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Econometrics/"><span class="tag">Econometrics</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/GPT-2/"><span class="tag">GPT-2</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/JetPack/"><span class="tag">JetPack</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Knative/"><span class="tag">Knative</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Kotlin/"><span class="tag">Kotlin</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/LaTeX/"><span class="tag">LaTeX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Log/"><span class="tag">Log</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Machine-Learning/"><span class="tag">Machine-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/NLP/"><span class="tag">NLP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/NMF/"><span class="tag">NMF</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Overview-of-AWS/"><span class="tag">Overview of AWS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/React/"><span class="tag">React</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Reinforce-Learning/"><span class="tag">Reinforce Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Serverless/"><span class="tag">Serverless</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Serverless-Terraform/"><span class="tag">Serverless - Terraform</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Spark/"><span class="tag">Spark</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Word2Vec/"><span class="tag">Word2Vec</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/Blog/img/self.jpg" alt="Haojun(Vincent) Gao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Haojun(Vincent) Gao</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/Blog/archives"><p class="title">50</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/Blog/categories"><p class="title">32</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/Blog/tags"><p class="title">37</p></a></div></div></nav></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/Blog/"><img src="/Blog/img/logo.jpg" alt="Gao Haojun" height="28"></a><p class="is-size-7"><span>&copy; 2025 Haojun(Vincent) Gao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Gallery" href="https://www.gaohaojun.com/"><i class="fab fa-fighter-jet"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Linkedin" href="https://www.instagram.com/vincent_gaohj/"><i class="fab fa-linkedin"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/vincent_gaohj/"><i class="fab fa-instagram"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/VincentGaoHJ"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/Blog/js/column.js"></script><script src="/Blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/Blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/Blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/Blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/Blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>
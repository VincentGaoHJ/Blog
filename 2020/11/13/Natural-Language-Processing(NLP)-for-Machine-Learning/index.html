<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>natural language processing(nlp) for machine learning | Gao Haojun</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Machine-LearningNatural-Language-Processing" />
  
  
  
  
  <meta name="description" content="Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, o">
<meta property="og:type" content="article">
<meta property="og:title" content="Natural Language Processing(NLP) for Machine Learning">
<meta property="og:url" content="http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/index.html">
<meta property="og:site_name" content="Gao Haojun">
<meta property="og:description" content="Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, o">
<meta property="og:locale">
<meta property="og:image" content="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/26106935459abe7c266f7b1ebfa2a824b334c807">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c233366865312bc99c832d1475e152c5074891b">
<meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/9c94f59b68f5ae0dc92185906c7ec4214fd04e1e">
<meta property="article:published_time" content="2020-11-13T04:53:22.000Z">
<meta property="article:modified_time" content="2021-01-17T07:33:42.000Z">
<meta property="article:author" content="Haojun(Vincent) Gao">
<meta property="article:tag" content="Machine-Learning">
<meta property="article:tag" content="Natural-Language-Processing">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png">
  
    <link rel="alternate" href="/atom.xml" title="Gao Haojun" type="application/atom+xml">
  

  

  <link rel="icon" href="/Blog/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/Blog/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/Blog/css/style.css">


  
<script src="/Blog/js/jquery-3.1.1.min.js"></script>

  
<script src="/Blog/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/Blog/css/bootstrap.css" >

  

  
  

  
    
<link rel="stylesheet" href="/Blog/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/Blog/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/Blog/css/vdonate.css" >
  

<meta name="generator" content="Hexo 5.2.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/Blog/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/Blog/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/Blog/',
        CONTENT_URL: '/Blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/Blog/js/insight.js"></script>


</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-Natural-Language-Processing(NLP)-for-Machine-Learning" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      Natural Language Processing(NLP) for Machine Learning
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/" class="article-date">
	  <time datetime="2020-11-13T04:53:22.000Z" itemprop="datePublished">2020-11-13</time>
	</a>

      
    <a class="article-category-link" href="/Blog/categories/Machine-Learning/">Machine Learning</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, otherwise known as text vectorization.</p>
<p><img src="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png" alt=""></p>
<a id="more"></a>
<p>[toc]</p>
<h2 id="Form-the-Dataset"><a href="#Form-the-Dataset" class="headerlink" title="Form the Dataset"></a>Form the Dataset</h2><p><strong>Positive Samples</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://transparency.twitter.com/en/reports/information-operations.html">Twitter Information Operations</a>: Insights into attempts to manipulate Twitter by state-backed entities.<ul>
<li>User Dataset: followers count, following count, account creation date, etc.</li>
<li>Tweets Dataset: tweets content, hash-tag, etc.</li>
</ul>
</li>
<li>Both of these two dataset have <code>user_id</code> which can tell us which tweets is belong to who. Base on this information, we could use all the tweets of a account as a feature of the user, and convert this feature into a numeric value which could directly used by machine learning model.</li>
</ul>
<p><strong>Negative Samples</strong></p>
<ul>
<li>User Dataset —  <a target="_blank" rel="noopener" href="https://www.oreilly.com/ideas/tweets-loud-and-quiet">“Tweets Loud and Quiet”</a> </li>
<li>Tweets Dataset — <a target="_blank" rel="noopener" href="http://help.sentiment140.com/for-students/">sentiment140</a></li>
<li>Those two dataset have no connection, but we could know the distribution of users information and tweets content separately. <strong>That’s also why we could use these two separate dataset to form the negative sample by simply sampling the tweets from tweets dataset to be the users tweets feature.</strong> the total number of tweets posted by user is told by the users dataset, as well as the frequency of user’s tweet behavior(calculated by total number divided by time horizon).</li>
</ul>
<p><strong>Sample of Natural Language Dataset</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>user_id(index)</th>
<th>follower_count</th>
<th>following_count</th>
<th>tweet_content</th>
<th>state-back label</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>32</td>
<td>1</td>
<td>@DiazCanelB: Campaign by MEPs against Cuba rejected in Belgium. Another instance of the Empire’s vulgar and interfering policy of subver… RT</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>45</td>
<td>@DiazCanelB: Fidel: “I keep in mind..that Bolivar was the man that José Martí most admired.</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2245</td>
<td>3332</td>
<td>#Style used to be an #interaction between the #human #soul and tools that were limiting.</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>0</td>
<td>#AI RT @couponfree01: #udemy Free Discount - The Complete Node.js Developer Course (3rd Edition)</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Sample of Numeric Dataset</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>user_id(index)</th>
<th>follower_count</th>
<th>following_count</th>
<th>against</th>
<th>campaign</th>
<th>…</th>
<th>Developer</th>
<th>mind</th>
<th>state-back label</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>32</td>
<td>1</td>
<td>0.63</td>
<td>0.77</td>
<td>…</td>
<td>0.65</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>45</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2245</td>
<td>3332</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0.64</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p><em>Note: the numeric value isn’t the number of time that word appear in the sample, it’s the TF-IDF value of the words. That’s why the values are decimal instead of integer. TF-IDF value will be introduced in the Vectorizing Data section, please find it below. The mean reason to do so is the reduce the dimension and also measure the feature of samples in a more scientific way</em></p>
<h2 id="Pre-processing-Data"><a href="#Pre-processing-Data" class="headerlink" title="Pre-processing Data"></a>Pre-processing Data</h2><h3 id="Remove-punctuation"><a href="#Remove-punctuation" class="headerlink" title="Remove punctuation"></a>Remove punctuation</h3><p>Punctuation can provide grammatical context to a sentence which supports our understanding. But for our vectorizer which counts the number of words and not the context, it does not add value, so we remove all special characters.</p>
<p><strong>e.g.: How are you?-&gt;How are you</strong></p>
<h3 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h3><p>Is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called <em>tokens</em>, and at the same time throwing away certain characters, such as punctuation.</p>
<h3 id="Remove-stopwords"><a href="#Remove-stopwords" class="headerlink" title="Remove stopwords"></a>Remove <a target="_blank" rel="noopener" href="http://kavita-ganesan.com/what-are-stop-words/#.X6lcQGgzZhE">stopwords</a></h3><p>Stopwords are common words that will likely appear in any text. They don’t tell us much about our data so we remove them. </p>
<p><strong>e.g.: silver or lead is fine for me-&gt; silver, lead, fine.</strong></p>
<p>we are passing two parameters to <a target="_blank" rel="noopener" href="https://kavita-ganesan.com/how-to-use-countvectorizer/">CountVectorizer</a>, <code>max_df</code> and <code>stop_words</code>. The first is just to say ignore all words that have appeared in 85% of the documents, since those may be unimportant. The later, is a custom stop words list. You can also use stop words that are native to sklearn by setting <code>stop_words=&#39;english&#39;</code>,.</p>
<h3 id="Lemmatizing"><a href="#Lemmatizing" class="headerlink" title="Lemmatizing"></a>Lemmatizing</h3><p>For grammatical reasons, documents are going to use different forms of a word, such as <em>organize</em>, <em>organizes</em>, and <em>organizing</em>. Additionally, there are families of derivationally related words with similar meanings, such as <em>democracy</em>, <em>democratic</em>, and <em>democratization</em>. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set</p>
<p>It is better than stemming as it uses a dictionary-based approach i.e a morphological analysis to the root word. </p>
<p><strong>e.g.: entitling, entitled -&gt; entitle</strong></p>
<h2 id="Vectorizing-Data"><a href="#Vectorizing-Data" class="headerlink" title="Vectorizing Data"></a>Vectorizing Data</h2><p>Vectorizing is the process of encoding text as integers i.e. numeric form to create feature vectors so that machine learning algorithms can understand our data.</p>
<h3 id="Bag-Of-Words"><a href="#Bag-Of-Words" class="headerlink" title="Bag-Of-Words"></a>Bag-Of-Words</h3><p>It gives a result of 1 if present in the sentence and 0 if not present. It, therefore, creates a bag of words with a document-matrix count in each text document.</p>
<h3 id="Extracting-features-with-TF-IDF"><a href="#Extracting-features-with-TF-IDF" class="headerlink" title="Extracting features with TF-IDF"></a>Extracting features with TF-IDF</h3><h4 id="Why-is-TF-IDF-used-in-Machine-Learning"><a href="#Why-is-TF-IDF-used-in-Machine-Learning" class="headerlink" title="Why is TF-IDF used in Machine Learning ?"></a>Why is TF-IDF used in Machine Learning ?</h4><p><a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/gentle-guide-to-machine-learning/">Machine learning</a> with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, otherwise known as <a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/beginners-guide-text-vectorization/">text vectorization</a>. It’s a fundamental step in the process of machine learning for <a target="_blank" rel="noopener" href="http://www.monkeylearn.com/data-analysis/">analyzing data</a>, and different vectorization algorithms will drastically affect end results, so you need to choose one that will deliver the results you’re hoping for.</p>
<h4 id="What-is-TF-IDF"><a href="#What-is-TF-IDF" class="headerlink" title="What is TF-IDF ?"></a>What is TF-IDF ?</h4><p>TF-IDF which stands for <strong>Term Frequency – Inverse Document Frequency</strong>. It is one of the most important techniques used for information retrieval to represent how important a specific word or phrase is to a given document. </p>
<p>The TF-IDF  value increases in proportion to the number of times a word appears in the document but is often offset by the frequency of the word in the corpus, which helps to adjust with respect to the fact that some words appear more frequently in general.</p>
<ul>
<li>The <strong>term frequency</strong> of a word in a document. There are several ways of calculating this frequency, with the simplest being a raw count of instances a word appears in a document. Then, there are ways to adjust the frequency, by length of a document, or by the raw frequency of the most frequent word in a document.</li>
<li>The <strong>inverse document frequency</strong> of the word across a set of documents. This means, how common or rare a word is in the entire document set. The closer it is to 0, the more common a word is. This metric can be calculated by taking the total number of documents, dividing it by the number of documents that contain a word, and calculating the logarithm.</li>
<li>So, if the word is very common and appears in many documents, this number will approach 0. Otherwise, it will approach 1.</li>
</ul>
<p>Multiplying these two numbers results in the TF-IDF score of a word in a document. The higher the score, the more relevant that word is in that particular document.</p>
<h4 id="Mathematical-Term"><a href="#Mathematical-Term" class="headerlink" title="Mathematical Term"></a>Mathematical Term</h4><p><strong>To put it in more formal mathematical terms</strong>, the TF-IDF score for the word t in the document d from the document set D is calculated as follows:</p>
<script type="math/tex; mode=display">
\begin{equation}
\text { tf-idf }(t, d, D)=t f(t, d) \cdot \text { idf }(t, D)
\end{equation}</script><p>where</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{array}{c}
t f(t, d)=\log (1+\text { freq }(t, d)) \\
i d f(t, D)=\log \left(\frac{N}{\operatorname{count}(d \in D: t \in d)}\right)
\end{array}
\end{equation}</script><p><a target="_blank" rel="noopener" href="https://www.quora.com/How-can-one-reduce-the-TFIDF-model-size-without-reducing-the-accuracy-significantly"><strong>How can one reduce the TFIDF model size?</strong></a></p>
<ul>
<li>The most effortless way is by filtering out infrequent words. You can achieve this by setting input arguments as follows: to use <code>min_df</code> to ignore terms that have a document frequency lower than the <code>min_df</code>. If float, the parameter represents a proportion of documents, integer absolute counts. When dealing with a relatively large corpus, using <code>min_df</code> of 5, 10, or 50 reduces the size of the vocabulary significantly while maintaining (or often improving) the accuracy.</li>
<li><code>max_features</code> To consider only the top <code>max_features</code> ordered by term frequency across the corpus. This is useful if you have strict limit on the size of TF-IDF transformed features (e.g. up to 100,000 TF-IDF features).</li>
</ul>
<h2 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h2><p>Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work.</p>
<p>I haven’t tried this work in our project. We could discuss how to do this part if we want the higher performance or want to dive deeply into the natural language processing.</p>
<p><strong>Some Basic Idea of Constructing Features:</strong></p>
<ul>
<li>The average length of tweets posted by user.</li>
<li>The average length of sentence(base on the intuition that the provocative sentence tend to have few words in a sentence to make a clear slogan).</li>
</ul>
<h2 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h2><ul>
<li><strong>Accuracy can be a misleading metric for imbalanced data sets.</strong> Consider a sample with 95 negative and 5 positive values. Classifying all values as negative in this case gives 0.95 accuracy score. </li>
<li><strong>Precision</strong>: In the field of information retrieval, precision is the fraction of retrieved documents that are relevant to the query.</li>
<li><strong>Recall</strong>: recall is the fraction of the relevant documents that are successfully retrieved.</li>
<li>Precision and recall are then defined as:</li>
</ul>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/26106935459abe7c266f7b1ebfa2a824b334c807" alt=""></p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c233366865312bc99c832d1475e152c5074891b" alt=""></p>
<ul>
<li><strong>F-measure</strong>: he traditional F-measure or balanced F-score (<strong>F1 score</strong>) is the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Harmonic_mean#Harmonic_mean_of_two_numbers">geometric(harmonic) mean</a> of precision and recall:</li>
</ul>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9c94f59b68f5ae0dc92185906c7ec4214fd04e1e" alt=""></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b">Natural Language Processing(NLP) for Machine Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/sklearn-feature-extraction-with-tf-idf/">Sklearn | Feature Extraction with TF-IDF</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@hritikattri10/feature-extraction-using-tf-idf-algorithm-44eedb37305e">Feature Extraction using TF-IDF algorithm</a></li>
<li><a target="_blank" rel="noopener" href="https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.X6lUVWgzZhE">Extracting Keywords with TF-IDF and Python’s Scikit-Learn</a></li>
<li><a target="_blank" rel="noopener" href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/">Twitter sentiment analysis using Python and NLTK</a></li>
<li><a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/what-is-tf-idf/">What is TF-IDF</a></li>
</ul>
<h2 id="Other-Useful-Dataset"><a href="#Other-Useful-Dataset" class="headerlink" title="Other Useful Dataset"></a>Other Useful Dataset</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/shaypal5/awesome-twitter-data">A list of Twitter datasets and related resources</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>


<script src="/Blog/js/vdonate.js"></script>

<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: 'Donate', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/WeChanQR.png',
  alipayImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/AliPayQR.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Haojun(Vincent) Gao</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/" target="_blank" title="Natural Language Processing(NLP) for Machine Learning">http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Machine-Learning/" rel="tag">Machine-Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Natural-Language-Processing/" rel="tag">Natural-Language-Processing</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/Blog/2020/12/08/Docker-Django-React-AWS-Deploying-Containerized-Application-to-Cloud/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Docker, Django, React, AWS: Deploying Containerized Application to Cloud
        
      </div>
    </a>
  
  
    <a href="/Blog/2020/11/06/A-Comprehensive-Look-at-The%20Multi-Armed-Bandit-Problem/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">A Comprehensive Look at The Multi-Armed Bandit Problem</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Form-the-Dataset"><span class="nav-number">1.</span> <span class="nav-text">Form the Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Pre-processing-Data"><span class="nav-number">2.</span> <span class="nav-text">Pre-processing Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Remove-punctuation"><span class="nav-number">2.1.</span> <span class="nav-text">Remove punctuation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tokenization"><span class="nav-number">2.2.</span> <span class="nav-text">Tokenization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Remove-stopwords"><span class="nav-number">2.3.</span> <span class="nav-text">Remove stopwords</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lemmatizing"><span class="nav-number">2.4.</span> <span class="nav-text">Lemmatizing</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Vectorizing-Data"><span class="nav-number">3.</span> <span class="nav-text">Vectorizing Data</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Bag-Of-Words"><span class="nav-number">3.1.</span> <span class="nav-text">Bag-Of-Words</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Extracting-features-with-TF-IDF"><span class="nav-number">3.2.</span> <span class="nav-text">Extracting features with TF-IDF</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Why-is-TF-IDF-used-in-Machine-Learning"><span class="nav-number">3.2.1.</span> <span class="nav-text">Why is TF-IDF used in Machine Learning ?</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#What-is-TF-IDF"><span class="nav-number">3.2.2.</span> <span class="nav-text">What is TF-IDF ?</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Mathematical-Term"><span class="nav-number">3.2.3.</span> <span class="nav-text">Mathematical Term</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Feature-Engineering"><span class="nav-number">4.</span> <span class="nav-text">Feature Engineering</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Metric"><span class="nav-number">5.</span> <span class="nav-text">Metric</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">6.</span> <span class="nav-text">Reference</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Other-Useful-Dataset"><span class="nav-number">7.</span> <span class="nav-text">Other Useful Dataset</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2022 Gao Haojun All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>



<!-- 2017.6.11，masikkk新增，加载本地Google Prettify 代码高亮js代码 -->

<!--
<script src="/Blog/js/prettify.js"></script>
-->

<!-- 2017.6.11，masikkk新增，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(window).load(function(){})是在页面所有元素(包括所有css,js,图片,Flash等)加载完毕后执行
<script type="text/javascript">
$(window).load(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->
<!-- 2017.7.1，masikkk添加，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(document).ready(function(){})是当页面的标准DOM元素被解析成DOM树后就执行 -->

<!--
<script type="text/javascript">
$(document).ready(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->

<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>



    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/Blog/" class="mobile-nav-link">Home</a>
  
    <a href="/Blog/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/Blog/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/Blog/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/Blog/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/Blog/fancybox/jquery.fancybox.css">

  
<script src="/Blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/Blog/js/scripts.js"></script>





  
<script src="/Blog/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Gao Haojun
          </div>
          <div class="panel-body">
            Copyright © 2022 Haojun(Vincent) Gao All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
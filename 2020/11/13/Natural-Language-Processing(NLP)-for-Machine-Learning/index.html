<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Natural Language Processing(NLP) for Machine Learning - Gao Haojun</title><link rel="manifest" href="/Blog/manifest.json"><meta name="application-name" content="Gao Haojun"><meta name="msapplication-TileImage" content="/img/favicon.jpeg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Gao Haojun"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, o"><meta property="og:type" content="blog"><meta property="og:title" content="Natural Language Processing(NLP) for Machine Learning"><meta property="og:url" content="http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/"><meta property="og:site_name" content="Gao Haojun"><meta property="og:description" content="Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, o"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png"><meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/26106935459abe7c266f7b1ebfa2a824b334c807"><meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c233366865312bc99c832d1475e152c5074891b"><meta property="og:image" content="https://wikimedia.org/api/rest_v1/media/math/render/svg/9c94f59b68f5ae0dc92185906c7ec4214fd04e1e"><meta property="article:published_time" content="2020-11-13T04:53:22.000Z"><meta property="article:modified_time" content="2022-02-22T04:46:10.390Z"><meta property="article:author" content="Haojun(Vincent) Gao"><meta property="article:tag" content="Machine-Learning"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/"},"headline":"Natural Language Processing(NLP) for Machine Learning","image":["https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png"],"datePublished":"2020-11-13T04:53:22.000Z","dateModified":"2022-02-22T04:46:10.390Z","author":{"@type":"Person","name":"Haojun(Vincent) Gao"},"publisher":{"@type":"Organization","name":"Gao Haojun","logo":{"@type":"ImageObject","url":"http://vincentgaohj.github.io/img/logo.jpg"}},"description":"Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, o"}</script><link rel="canonical" href="http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/"><link rel="icon" href="/Blog/img/favicon.jpeg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/Blog/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.0.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/Blog/"><img src="/Blog/img/logo.jpg" alt="Gao Haojun" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/Blog/">Home</a><a class="navbar-item" href="/Blog/archives">Archives</a><a class="navbar-item" href="/Blog/categories">Categories</a><a class="navbar-item" href="/Blog/tags">Tags</a><a class="navbar-item" href="/Blog/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/VincentGaoHJ"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-11-13T04:53:22.000Z" title="2020-11-13 12:53:22 ├F10: PM┤">2020-11-13</time></span><span class="level-item"><a class="link-muted" href="/Blog/categories/Algorithm/">Algorithm</a><span> / </span><a class="link-muted" href="/Blog/categories/Algorithm/Natural-Language-Processing/">Natural Language Processing</a></span><span class="level-item">12 minutes read (About 1777 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Natural Language Processing(NLP) for Machine Learning</h1><div class="content"><p>Machine learning with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, otherwise known as text vectorization.</p>
<p><img src="https://monkeylearn.com/static/d7073ac089cd3ea6dff4c1645446f91a/05b00/Getting-started-in-NLP.png" alt=""></p>
<span id="more"></span>
<p>[toc]</p>
<h2 id="Form-the-Dataset"><a href="#Form-the-Dataset" class="headerlink" title="Form the Dataset"></a>Form the Dataset</h2><p><strong>Positive Samples</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://transparency.twitter.com/en/reports/information-operations.html">Twitter Information Operations</a>: Insights into attempts to manipulate Twitter by state-backed entities.<ul>
<li>User Dataset: followers count, following count, account creation date, etc.</li>
<li>Tweets Dataset: tweets content, hash-tag, etc.</li>
</ul>
</li>
<li>Both of these two dataset have <code>user_id</code> which can tell us which tweets is belong to who. Base on this information, we could use all the tweets of a account as a feature of the user, and convert this feature into a numeric value which could directly used by machine learning model.</li>
</ul>
<p><strong>Negative Samples</strong></p>
<ul>
<li>User Dataset —  <a target="_blank" rel="noopener" href="https://www.oreilly.com/ideas/tweets-loud-and-quiet">“Tweets Loud and Quiet”</a> </li>
<li>Tweets Dataset — <a target="_blank" rel="noopener" href="http://help.sentiment140.com/for-students/">sentiment140</a></li>
<li>Those two dataset have no connection, but we could know the distribution of users information and tweets content separately. <strong>That’s also why we could use these two separate dataset to form the negative sample by simply sampling the tweets from tweets dataset to be the users tweets feature.</strong> the total number of tweets posted by user is told by the users dataset, as well as the frequency of user’s tweet behavior(calculated by total number divided by time horizon).</li>
</ul>
<p><strong>Sample of Natural Language Dataset</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>user_id(index)</th>
<th>follower_count</th>
<th>following_count</th>
<th>tweet_content</th>
<th>state-back label</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>32</td>
<td>1</td>
<td>@DiazCanelB: Campaign by MEPs against Cuba rejected in Belgium. Another instance of the Empire’s vulgar and interfering policy of subver… RT</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>45</td>
<td>@DiazCanelB: Fidel: “I keep in mind..that Bolivar was the man that José Martí most admired.</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2245</td>
<td>3332</td>
<td>#Style used to be an #interaction between the #human #soul and tools that were limiting.</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>0</td>
<td>#AI RT @couponfree01: #udemy Free Discount - The Complete Node.js Developer Course (3rd Edition)</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p><strong>Sample of Numeric Dataset</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>user_id(index)</th>
<th>follower_count</th>
<th>following_count</th>
<th>against</th>
<th>campaign</th>
<th>…</th>
<th>Developer</th>
<th>mind</th>
<th>state-back label</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>32</td>
<td>1</td>
<td>0.63</td>
<td>0.77</td>
<td>…</td>
<td>0.65</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>45</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>2245</td>
<td>3332</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0.64</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p><em>Note: the numeric value isn’t the number of time that word appear in the sample, it’s the TF-IDF value of the words. That’s why the values are decimal instead of integer. TF-IDF value will be introduced in the Vectorizing Data section, please find it below. The mean reason to do so is the reduce the dimension and also measure the feature of samples in a more scientific way</em></p>
<h2 id="Pre-processing-Data"><a href="#Pre-processing-Data" class="headerlink" title="Pre-processing Data"></a>Pre-processing Data</h2><h3 id="Remove-punctuation"><a href="#Remove-punctuation" class="headerlink" title="Remove punctuation"></a>Remove punctuation</h3><p>Punctuation can provide grammatical context to a sentence which supports our understanding. But for our vectorizer which counts the number of words and not the context, it does not add value, so we remove all special characters.</p>
<p><strong>e.g.: How are you?-&gt;How are you</strong></p>
<h3 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h3><p>Is the process of segmenting running text into sentences and words. In essence, it’s the task of cutting a text into pieces called <em>tokens</em>, and at the same time throwing away certain characters, such as punctuation.</p>
<h3 id="Remove-stopwords"><a href="#Remove-stopwords" class="headerlink" title="Remove stopwords"></a>Remove <a target="_blank" rel="noopener" href="http://kavita-ganesan.com/what-are-stop-words/#.X6lcQGgzZhE">stopwords</a></h3><p>Stopwords are common words that will likely appear in any text. They don’t tell us much about our data so we remove them. </p>
<p><strong>e.g.: silver or lead is fine for me-&gt; silver, lead, fine.</strong></p>
<p>we are passing two parameters to <a target="_blank" rel="noopener" href="https://kavita-ganesan.com/how-to-use-countvectorizer/">CountVectorizer</a>, <code>max_df</code> and <code>stop_words</code>. The first is just to say ignore all words that have appeared in 85% of the documents, since those may be unimportant. The later, is a custom stop words list. You can also use stop words that are native to sklearn by setting <code>stop_words=&#39;english&#39;</code>,.</p>
<h3 id="Lemmatizing"><a href="#Lemmatizing" class="headerlink" title="Lemmatizing"></a>Lemmatizing</h3><p>For grammatical reasons, documents are going to use different forms of a word, such as <em>organize</em>, <em>organizes</em>, and <em>organizing</em>. Additionally, there are families of derivationally related words with similar meanings, such as <em>democracy</em>, <em>democratic</em>, and <em>democratization</em>. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set</p>
<p>It is better than stemming as it uses a dictionary-based approach i.e a morphological analysis to the root word. </p>
<p><strong>e.g.: entitling, entitled -&gt; entitle</strong></p>
<h2 id="Vectorizing-Data"><a href="#Vectorizing-Data" class="headerlink" title="Vectorizing Data"></a>Vectorizing Data</h2><p>Vectorizing is the process of encoding text as integers i.e. numeric form to create feature vectors so that machine learning algorithms can understand our data.</p>
<h3 id="Bag-Of-Words"><a href="#Bag-Of-Words" class="headerlink" title="Bag-Of-Words"></a>Bag-Of-Words</h3><p>It gives a result of 1 if present in the sentence and 0 if not present. It, therefore, creates a bag of words with a document-matrix count in each text document.</p>
<h3 id="Extracting-features-with-TF-IDF"><a href="#Extracting-features-with-TF-IDF" class="headerlink" title="Extracting features with TF-IDF"></a>Extracting features with TF-IDF</h3><h4 id="Why-is-TF-IDF-used-in-Machine-Learning"><a href="#Why-is-TF-IDF-used-in-Machine-Learning" class="headerlink" title="Why is TF-IDF used in Machine Learning ?"></a>Why is TF-IDF used in Machine Learning ?</h4><p><a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/gentle-guide-to-machine-learning/">Machine learning</a> with natural language is faced with one major hurdle – its algorithms usually deal with numbers, and natural language is, well, text. So we need to transform that text into numbers, otherwise known as <a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/beginners-guide-text-vectorization/">text vectorization</a>. It’s a fundamental step in the process of machine learning for <a target="_blank" rel="noopener" href="http://www.monkeylearn.com/data-analysis/">analyzing data</a>, and different vectorization algorithms will drastically affect end results, so you need to choose one that will deliver the results you’re hoping for.</p>
<h4 id="What-is-TF-IDF"><a href="#What-is-TF-IDF" class="headerlink" title="What is TF-IDF ?"></a>What is TF-IDF ?</h4><p>TF-IDF which stands for <strong>Term Frequency – Inverse Document Frequency</strong>. It is one of the most important techniques used for information retrieval to represent how important a specific word or phrase is to a given document. </p>
<p>The TF-IDF  value increases in proportion to the number of times a word appears in the document but is often offset by the frequency of the word in the corpus, which helps to adjust with respect to the fact that some words appear more frequently in general.</p>
<ul>
<li>The <strong>term frequency</strong> of a word in a document. There are several ways of calculating this frequency, with the simplest being a raw count of instances a word appears in a document. Then, there are ways to adjust the frequency, by length of a document, or by the raw frequency of the most frequent word in a document.</li>
<li>The <strong>inverse document frequency</strong> of the word across a set of documents. This means, how common or rare a word is in the entire document set. The closer it is to 0, the more common a word is. This metric can be calculated by taking the total number of documents, dividing it by the number of documents that contain a word, and calculating the logarithm.</li>
<li>So, if the word is very common and appears in many documents, this number will approach 0. Otherwise, it will approach 1.</li>
</ul>
<p>Multiplying these two numbers results in the TF-IDF score of a word in a document. The higher the score, the more relevant that word is in that particular document.</p>
<h4 id="Mathematical-Term"><a href="#Mathematical-Term" class="headerlink" title="Mathematical Term"></a>Mathematical Term</h4><p><strong>To put it in more formal mathematical terms</strong>, the TF-IDF score for the word t in the document d from the document set D is calculated as follows:</p>
<script type="math/tex; mode=display">
\begin{equation}
\text { tf-idf }(t, d, D)=t f(t, d) \cdot \text { idf }(t, D)
\end{equation}</script><p>where</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{array}{c}
t f(t, d)=\log (1+\text { freq }(t, d)) \\
i d f(t, D)=\log \left(\frac{N}{\operatorname{count}(d \in D: t \in d)}\right)
\end{array}
\end{equation}</script><p><a target="_blank" rel="noopener" href="https://www.quora.com/How-can-one-reduce-the-TFIDF-model-size-without-reducing-the-accuracy-significantly"><strong>How can one reduce the TFIDF model size?</strong></a></p>
<ul>
<li>The most effortless way is by filtering out infrequent words. You can achieve this by setting input arguments as follows: to use <code>min_df</code> to ignore terms that have a document frequency lower than the <code>min_df</code>. If float, the parameter represents a proportion of documents, integer absolute counts. When dealing with a relatively large corpus, using <code>min_df</code> of 5, 10, or 50 reduces the size of the vocabulary significantly while maintaining (or often improving) the accuracy.</li>
<li><code>max_features</code> To consider only the top <code>max_features</code> ordered by term frequency across the corpus. This is useful if you have strict limit on the size of TF-IDF transformed features (e.g. up to 100,000 TF-IDF features).</li>
</ul>
<h2 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h2><p>Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work.</p>
<p>I haven’t tried this work in our project. We could discuss how to do this part if we want the higher performance or want to dive deeply into the natural language processing.</p>
<p><strong>Some Basic Idea of Constructing Features:</strong></p>
<ul>
<li>The average length of tweets posted by user.</li>
<li>The average length of sentence(base on the intuition that the provocative sentence tend to have few words in a sentence to make a clear slogan).</li>
</ul>
<h2 id="Metric"><a href="#Metric" class="headerlink" title="Metric"></a>Metric</h2><ul>
<li><strong>Accuracy can be a misleading metric for imbalanced data sets.</strong> Consider a sample with 95 negative and 5 positive values. Classifying all values as negative in this case gives 0.95 accuracy score. </li>
<li><strong>Precision</strong>: In the field of information retrieval, precision is the fraction of retrieved documents that are relevant to the query.</li>
<li><strong>Recall</strong>: recall is the fraction of the relevant documents that are successfully retrieved.</li>
<li>Precision and recall are then defined as:</li>
</ul>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/26106935459abe7c266f7b1ebfa2a824b334c807" alt=""></p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c233366865312bc99c832d1475e152c5074891b" alt=""></p>
<ul>
<li><strong>F-measure</strong>: he traditional F-measure or balanced F-score (<strong>F1 score</strong>) is the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Harmonic_mean#Harmonic_mean_of_two_numbers">geometric(harmonic) mean</a> of precision and recall:</li>
</ul>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9c94f59b68f5ae0dc92185906c7ec4214fd04e1e" alt=""></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b">Natural Language Processing(NLP) for Machine Learning</a></li>
<li><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/sklearn-feature-extraction-with-tf-idf/">Sklearn | Feature Extraction with TF-IDF</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@hritikattri10/feature-extraction-using-tf-idf-algorithm-44eedb37305e">Feature Extraction using TF-IDF algorithm</a></li>
<li><a target="_blank" rel="noopener" href="https://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.X6lUVWgzZhE">Extracting Keywords with TF-IDF and Python’s Scikit-Learn</a></li>
<li><a target="_blank" rel="noopener" href="http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/">Twitter sentiment analysis using Python and NLTK</a></li>
<li><a target="_blank" rel="noopener" href="https://monkeylearn.com/blog/what-is-tf-idf/">What is TF-IDF</a></li>
</ul>
<h2 id="Other-Useful-Dataset"><a href="#Other-Useful-Dataset" class="headerlink" title="Other Useful Dataset"></a>Other Useful Dataset</h2><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/shaypal5/awesome-twitter-data">A list of Twitter datasets and related resources</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Natural Language Processing(NLP) for Machine Learning</p><p><a href="http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/">http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Haojun(Vincent) Gao</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-11-13</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-02-22</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-globe"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/Blog/tags/Machine-Learning/">Machine-Learning</a><a class="link-muted mr-2" rel="tag" href="/Blog/tags/NLP/">NLP</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=62145317b846610019d3dc05&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/@vincent_gaohj" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>Afdian.net</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/Blog/img/alipay.jpg" alt="Alipay"></span></a><a class="button donate" href="https://www.buymeacoffee.com/gaohaojun" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Blog/2020/12/08/Docker-Django-React-AWS-Deploying-Containerized-Application-to-Cloud/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Docker, Django, React, AWS: Deploying Containerized Application to Cloud</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Blog/2020/11/06/A-Comprehensive-Look-at-The%20Multi-Armed-Bandit-Problem/"><span class="level-item">A Comprehensive Look at The Multi-Armed Bandit Problem</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'http://vincentgaohj.github.io/Blog/2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/';
            this.page.identifier = '2020/11/13/Natural-Language-Processing(NLP)-for-Machine-Learning/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'vincentgaohj' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><figure class="media-left"><a class="image" href="/Blog/2022/02/16/Overview-of-AWS-Machine-Learning-Services/"><img src="/Blog/gallery/Overview-of-AWS-Machine-Learning-Services/cover.jpg" alt="Overview of AWS: Machine Learning Services (2022 Edition)"></a></figure><div class="media-content"><p class="date"><time dateTime="2022-02-16T06:02:44.000Z">2022-02-16</time></p><p class="title"><a href="/Blog/2022/02/16/Overview-of-AWS-Machine-Learning-Services/">Overview of AWS: Machine Learning Services (2022 Edition)</a></p><p class="categories"><a href="/Blog/categories/AWS/">AWS</a> / <a href="/Blog/categories/AWS/Overview/">Overview</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/"><img src="/Blog/gallery/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/cover.png" alt="LAMBADA Method: How to use Data Augmentation in NLU?"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-10-30T14:44:24.000Z">2021-10-30</time></p><p class="title"><a href="/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/">LAMBADA Method: How to use Data Augmentation in NLU?</a></p><p class="categories"><a href="/Blog/categories/Algorithm/">Algorithm</a> / <a href="/Blog/categories/Algorithm/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/Blog/2021/10/26/Not-Enough-Data-Deep-Learning-to-the-Rescue/"><img src="/Blog/gallery/Not-Enough-Data-Deep-Learning-to-the-Rescue/cover.jpg" alt="Not Enough Data? Deep Learning to the Rescue!"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-10-26T14:44:24.000Z">2021-10-26</time></p><p class="title"><a href="/Blog/2021/10/26/Not-Enough-Data-Deep-Learning-to-the-Rescue/">Not Enough Data? Deep Learning to the Rescue!</a></p><p class="categories"><a href="/Blog/categories/Algorithm/">Algorithm</a> / <a href="/Blog/categories/Algorithm/Natural-Language-Processing/">Natural Language Processing</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-08-04T03:19:15.000Z">2021-08-04</time></p><p class="title"><a href="/Blog/2021/08/04/Modern-Android-Architecture-via-MVVM-JetPack/">Modern Android Architecture via MVVM + JetPack</a></p><p class="categories"><a href="/Blog/categories/Development/">Development</a> / <a href="/Blog/categories/Development/Android/">Android</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-03T05:08:59.000Z">2021-07-03</time></p><p class="title"><a href="/Blog/2021/07/03/Mastering-AWS-SAM/">Mastering AWS SAM: The AWS Serverless Application Model</a></p><p class="categories"><a href="/Blog/categories/AWS/">AWS</a> / <a href="/Blog/categories/AWS/Architecture/">Architecture</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/Blog/categories/AWS/"><span class="level-start"><span class="level-item">AWS</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/AWS/AWS-Certified-Machine-Learning-Specialty/"><span class="level-start"><span class="level-item">AWS Certified Machine Learning Specialty</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/AWS-Certified-Solution-Architect-Associate/"><span class="level-start"><span class="level-item">AWS Certified Solution Architect Associate</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/Architecture/"><span class="level-start"><span class="level-item">Architecture</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/AWS/Overview/"><span class="level-start"><span class="level-item">Overview</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/NMF/"><span class="level-start"><span class="level-item">NMF</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Natural-Language-Processing/"><span class="level-start"><span class="level-item">Natural Language Processing</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Algorithm/Reinforce-Learning/"><span class="level-start"><span class="level-item">Reinforce Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Big-Data/"><span class="level-start"><span class="level-item">Big Data</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Big-Data/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/Development/"><span class="level-start"><span class="level-item">Development</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Development/Android/"><span class="level-start"><span class="level-item">Android</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/Full-Stack/"><span class="level-start"><span class="level-item">Full Stack</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/Log-Stack/"><span class="level-start"><span class="level-item">Log Stack</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Development/SQL/"><span class="level-start"><span class="level-item">SQL</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/English-Study/"><span class="level-start"><span class="level-item">English Study</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Finance/"><span class="level-start"><span class="level-item">Finance</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/Blog/categories/Finance/Asset-Management/"><span class="level-start"><span class="level-item">Asset Management</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Finance/Econometrics/"><span class="level-start"><span class="level-item">Econometrics</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/Blog/categories/LaTeX/"><span class="level-start"><span class="level-item">LaTeX</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/Blog/categories/Lifestyle/"><span class="level-start"><span class="level-item">Lifestyle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/Blog/tags/AWS/"><span class="tag">AWS</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/AWS-Serverless/"><span class="tag">AWS - Serverless</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Android/"><span class="tag">Android</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Apps/"><span class="tag">Apps</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/CNN/"><span class="tag">CNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Certified/"><span class="tag">Certified</span><span class="tag">10</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Certified-Machine-Learning-Specialty/"><span class="tag">Certified Machine Learning - Specialty</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Clustering/"><span class="tag">Clustering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Coffee/"><span class="tag">Coffee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Deep-Learning/"><span class="tag">Deep-Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Django/"><span class="tag">Django</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/EKK/"><span class="tag">EKK</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Econometrics/"><span class="tag">Econometrics</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/GPT-2/"><span class="tag">GPT-2</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/JetPack/"><span class="tag">JetPack</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Kotlin/"><span class="tag">Kotlin</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/LaTeX/"><span class="tag">LaTeX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Log/"><span class="tag">Log</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Machine-Learning/"><span class="tag">Machine-Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/NLP/"><span class="tag">NLP</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/NMF/"><span class="tag">NMF</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Overview-of-AWS/"><span class="tag">Overview of AWS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/React/"><span class="tag">React</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Reinforce-Learning/"><span class="tag">Reinforce Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Serverless/"><span class="tag">Serverless</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Spark/"><span class="tag">Spark</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/TOEFL/"><span class="tag">TOEFL</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/Blog/tags/Word2Vec/"><span class="tag">Word2Vec</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/Blog/img/avatar.png" alt="Haojun(Vincent) Gao"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Haojun(Vincent) Gao</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/Blog/archives"><p class="title">43</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/Blog/categories"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/Blog/tags"><p class="title">33</p></a></div></div></nav></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/Blog/"><img src="/Blog/img/logo.jpg" alt="Gao Haojun" height="28"></a><p class="is-size-7"><span>&copy; 2022 Haojun(Vincent) Gao</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Gallery" href="https://www.gaohaojun.com/"><i class="fab fa-fighter-jet"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Linkedin" href="https://www.instagram.com/vincent_gaohj/"><i class="fab fa-linkedin"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/vincent_gaohj/"><i class="fab fa-instagram"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/VincentGaoHJ"><i class="fab fa-github"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/Blog/js/column.js"></script><script src="/Blog/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/Blog/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/Blog/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/Blog/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/Blog/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>
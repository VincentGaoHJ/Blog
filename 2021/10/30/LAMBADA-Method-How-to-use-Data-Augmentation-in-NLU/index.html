<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>lambada method: how to use data augmentation in nlu? | Gao Haojun</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="Deep LearningMachine LearningBERTGPT-2Natural Language ProcessingNetural Language Generation" />
  
  
  
  
  <meta name="description" content="In this tutorial, I will walk you through the implementation to reproduce LAMBADA. From my previous article, which illustrate the basic idea of LAMBADA method that leverage Natural Language Generation">
<meta property="og:type" content="article">
<meta property="og:title" content="LAMBADA Method: How to use Data Augmentation in NLU?">
<meta property="og:url" content="http://vincentgaohj.github.io/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/index.html">
<meta property="og:site_name" content="Gao Haojun">
<meta property="og:description" content="In this tutorial, I will walk you through the implementation to reproduce LAMBADA. From my previous article, which illustrate the basic idea of LAMBADA method that leverage Natural Language Generation">
<meta property="og:locale">
<meta property="og:image" content="https://cdn-images-1.medium.com/max/1000/1*C8hNiOqur4OJyEZmC7OnzQ.png">
<meta property="article:published_time" content="2021-10-30T14:44:24.000Z">
<meta property="article:modified_time" content="2021-12-01T18:15:27.310Z">
<meta property="article:author" content="Haojun(Vincent) Gao">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="GPT-2">
<meta property="article:tag" content="Natural Language Processing">
<meta property="article:tag" content="Netural Language Generation">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn-images-1.medium.com/max/1000/1*C8hNiOqur4OJyEZmC7OnzQ.png">
  
    <link rel="alternate" href="/atom.xml" title="Gao Haojun" type="application/atom+xml">
  

  

  <link rel="icon" href="/Blog/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/Blog/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/Blog/css/style.css">


  
<script src="/Blog/js/jquery-3.1.1.min.js"></script>

  
<script src="/Blog/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/Blog/css/bootstrap.css" >

  

  
  

  
    
<link rel="stylesheet" href="/Blog/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/Blog/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/Blog/css/vdonate.css" >
  

<meta name="generator" content="Hexo 5.2.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/Blog/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/Blog/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/Blog/',
        CONTENT_URL: '/Blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/Blog/js/insight.js"></script>


</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      LAMBADA Method: How to use Data Augmentation in NLU?
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/" class="article-date">
	  <time datetime="2021-10-30T14:44:24.000Z" itemprop="datePublished">2021-10-30</time>
	</a>

      
    <a class="article-category-link" href="/Blog/categories/Deep-Learning/">Deep Learning</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>In this tutorial, I will walk you through the implementation to reproduce LAMBADA.</strong></p>
<p>From my previous article, which illustrate the basic idea of LAMBADA method that leverage Natural Language Generation(NLG) to  boost training set for the Natural Language Understanding(NLU) task including text classification.</p>
<p><img src="https://cdn-images-1.medium.com/max/1000/1*C8hNiOqur4OJyEZmC7OnzQ.png" alt="Image by bagoftricks"></p>
<a id="more"></a>
<p>Before you dive into the code fragment, you may have a look at my previous article about the basic idea of the LAMBADA, including the fundamental thinking, and the workflow. </p>
<h1 id="Step-1-Preparation"><a href="#Step-1-Preparation" class="headerlink" title="Step 1: Preparation"></a>Step 1: Preparation</h1><ul>
<li>We use <code>distilBERT</code> as a classification model and <code>GPT-2</code> as text generation model. For both, we load pretrained weights and fine tune them.</li>
<li>In case of <code>GPT-2</code> we apply the Huggingface Transfomers library to bootstrap a pretrained model and subsequently to fine-tune it.</li>
<li>To load and fine-tune DistilBERT we use Ktrain, a library that provides a high-level interface for language models, eliminating the need to worry about tokenization and other pre-processing tasks.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!pip install ktrain</span><br><span class="line">!pip install transformers</span><br><span class="line">!pip install tensorflow</span><br></pre></td></tr></table></figure>
<h1 id="Step-2-Load-Data"><a href="#Step-2-Load-Data" class="headerlink" title="Step 2: Load Data"></a>Step 2: Load Data</h1><p>Then, we load the data from the csv file, which can be obtained from my repository. We split it into train set, valid set, and test set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">labels = data_train[<span class="string">&#x27;Label&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line">X_train, X_valid, X_test, y_train, y_valid, y_test = [], [], [], [], [], []</span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">    intent_X_train, intent_X_valid, intent_y_train, intent_y_valid = train_test_split(</span><br><span class="line">        data_train[data_train[<span class="string">&#x27;Label&#x27;</span>] == label][<span class="string">&#x27;Text&#x27;</span>],</span><br><span class="line">        data_train[data_train[<span class="string">&#x27;Label&#x27;</span>] == label][<span class="string">&#x27;Label&#x27;</span>],</span><br><span class="line">        train_size=<span class="number">0.8</span>,</span><br><span class="line">        random_state=<span class="number">43</span>)</span><br><span class="line">    intent_X_valid, intent_X_test, intent_y_valid, intent_y_test = train_test_split(</span><br><span class="line">        intent_X_valid, intent_y_valid,</span><br><span class="line">        train_size=<span class="number">0.5</span>,</span><br><span class="line">        random_state=<span class="number">43</span>)</span><br><span class="line">    X_train.extend(intent_X_train)</span><br><span class="line">    X_valid.extend(intent_X_valid)</span><br><span class="line">    X_test.extend(intent_X_test)</span><br><span class="line">    y_train.extend(intent_y_train)</span><br><span class="line">    y_valid.extend(intent_y_valid)</span><br><span class="line">    y_test.extend(intent_y_test)</span><br></pre></td></tr></table></figure>
<p>You can see the labels are:</p>
<blockquote>
<p>array([‘<strong>label</strong>15’, ‘<strong>label</strong>7’, ‘<strong>label</strong>0’, ‘<strong>label</strong>13’,  ‘<strong>label</strong>9’, ‘<strong>label</strong>8’, ‘<strong>label</strong>2’, ‘<strong>label</strong>4’,  ‘<strong>label</strong>1’, ‘<strong>label</strong>10’, ‘<strong>label</strong>5’, ‘<strong>label</strong>3’,<br>       ‘<strong>label</strong>14’, ‘<strong>label</strong>11’, ‘<strong>label</strong>12’, ‘<strong>label</strong>6’], dtype=object)</p>
</blockquote>
<h1 id="Step-3-Training-the-Initial-Intent-Classifier-BERT"><a href="#Step-3-Training-the-Initial-Intent-Classifier-BERT" class="headerlink" title="Step 3: Training the Initial Intent Classifier (BERT)"></a>Step 3: Training the Initial Intent Classifier (BERT)</h1><h2 id="3-1-Initialize-model-and-learner"><a href="#3-1-Initialize-model-and-learner" class="headerlink" title="3.1 Initialize model and learner"></a>3.1 Initialize model and learner</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> ktrain</span><br><span class="line"><span class="keyword">from</span> ktrain <span class="keyword">import</span> text</span><br></pre></td></tr></table></figure>
<p>We download the pretrained DistilBERT model, transform the training and validation data from pure text into the valid format for our model and initialize a learner object, which is used in KTrain to train the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">distil_bert = text.Transformer(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, </span><br><span class="line">                               maxlen=<span class="number">50</span>, </span><br><span class="line">                               class_names=labels)</span><br><span class="line">                               </span><br><span class="line">processed_train = distil_bert.preprocess_train(X_train, y_train)</span><br><span class="line">processed_test = distil_bert.preprocess_test(X_valid, y_valid)</span><br><span class="line"></span><br><span class="line">model = distil_bert.get_classifier()</span><br><span class="line">learner = ktrain.get_learner(</span><br><span class="line">    model, train_data=processed_train, val_data=processed_test, batch_size=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<h2 id="3-2-Train-classifier"><a href="#3-2-Train-classifier" class="headerlink" title="3.2 Train classifier"></a>3.2 Train classifier</h2><ul>
<li>Train classifier for given learning rate and number of epochs.</li>
<li>The number of epochs chosen depends on the size of your training data set.</li>
<li>Make sure to monitor the accuracies and losses!</li>
</ul>
<p>Now it’s time to train the model. We feed the training data to the network multiple times, specified by the number of epochs. In the beginning both monitored metrics, namely the loss function (decrease) and the accuracy (increase), should indicate improvement of the model with each epoch passed. However, after training the model for a while the validation loss will increase and the validation accuracy drop. This is a result of overfitting the training data and it is time to stop feeding the same data to the network.</p>
<p>The optimal number of epochs depends on your data set, model and training parameters. If you do not know the right number of epochs beforehand you can use a high number of epochs and activate checkpoints by setting the checkpoint_folder parameter to select the best performing model afterwards.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">N_TRAINING_EPOCHS = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">learner.fit_onecycle(<span class="number">5e-5</span>, N_TRAINING_EPOCHS)</span><br></pre></td></tr></table></figure>
<h2 id="3-3-Evaluate-trained-predictor"><a href="#3-3-Evaluate-trained-predictor" class="headerlink" title="3.3 Evaluate trained predictor"></a>3.3 Evaluate trained predictor</h2><p>To check the performance of our trained classifier, we use our test data in the <code>eval.csv</code> file.</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">predictor</span> = ktrain.get_predictor(learner.model, <span class="attr">preproc=distil_bert)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">predictions</span> = predictor.predict(X_test)</span><br><span class="line"><span class="attr">np_test_intents</span> = np.array(y_test)</span><br><span class="line"><span class="attr">np_predictions</span> = np.array(predictions)</span><br><span class="line"></span><br><span class="line"><span class="attr">result</span> = (<span class="attr">np_test_intents</span> == np_predictions)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Accuracy: &#123;:.2f&#125;%&quot;</span>.format(result.sum()/len(result)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<p><em>Note that thanks to the KTrain interface we can simply feed the list of utterances to the predictor without the need to pre-process the raw strings beforehand.</em></p>
<h2 id="3-4-Prepare-model-for-download"><a href="#3-4-Prepare-model-for-download" class="headerlink" title="3.4 Prepare model for download"></a>3.4 Prepare model for download</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line">predictor.save(<span class="string">&#x27;models/initial/distilbert_&#123;&#125;epochs_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">    N_TRAINING_EPOCHS, </span><br><span class="line">    datetime.datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S&quot;</span>)))</span><br><span class="line"></span><br><span class="line">!<span class="built_in">zip</span> -r -X distilbert_initial.<span class="built_in">zip</span> models/initial</span><br></pre></td></tr></table></figure>
<h1 id="Step-4-Fine-tune-GPT-2-to-generate-utterances"><a href="#Step-4-Fine-tune-GPT-2-to-generate-utterances" class="headerlink" title="Step 4:  Fine-tune GPT-2 to generate utterances"></a>Step 4:  Fine-tune GPT-2 to generate utterances</h1><h2 id="4-1-Fine-tune-GPT-2"><a href="#4-1-Fine-tune-GPT-2" class="headerlink" title="4.1 Fine-tune GPT-2"></a>4.1 Fine-tune GPT-2</h2><p>To fine-tune GPT-2, we use a Python script made available by Huggingface on their Github repository: <a target="_blank" rel="noopener" href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers</a></p>
<p>Put transformed dataset in directory where this jupyter notebook located at in order to run python script smoothly.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">utterance_file = data_train[[<span class="string">&#x27;Label&#x27;</span>, <span class="string">&#x27;Text&#x27;</span>]]</span><br><span class="line">path = <span class="string">&#x27;content&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</span><br><span class="line">    print(<span class="string">f&#x27;Create directory: <span class="subst">&#123;path&#125;</span>&#x27;</span>)</span><br><span class="line">    os.mkdir(path)</span><br><span class="line">save_to_csv(utterance_file, <span class="string">&#x27;train.csv&#x27;</span>, path)</span><br><span class="line">print(<span class="string">&#x27;Save training file successfully&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Among others, we specify the following parameters:</strong></p>
<ul>
<li><strong>the pretrained model that we want to use (gpt2-medium).</strong> Larger models, typically generate better text outputs. Please note, these models require a large amount of memory during training, so make sure you pick a model that fits into your (GPU-)memory.</li>
<li><strong>the number of epochs.</strong> This parameter specifies how many times the training data is fed through the network. On the one hand, if the number of epochs is too small, the model will not learn to generate useful utterances. On the other hand, if the number is chosen too big, the model will likely overfit and the variability in the generated text data will be limited – the model will basically just remember the training data.</li>
<li><strong>the batch size.</strong> This determines how many utterances are used for training in parallel. The larger the batch size the faster the training, larger batch sizes require more memory, though.</li>
<li><strong>the block size.</strong> The block size defines an upper bound on the number of tokens considered from each training data instance that are used. Make sure that this number is sufficient so that utterances are not cropped.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!python finetune_gpt.py \</span><br><span class="line">    --output_dir=.//content//transformers//output \</span><br><span class="line">    --model_type=gpt2-medium \</span><br><span class="line">    --model_name_or_path=gpt2-medium \</span><br><span class="line">    --num_train_epochs=<span class="number">3.0</span> \</span><br><span class="line">    --do_train \</span><br><span class="line">    --train_data_file=.//content//train.csv \</span><br><span class="line">    --per_gpu_train_batch_size=<span class="number">4</span> \</span><br><span class="line">    --block_size=<span class="number">50</span> \</span><br><span class="line">    --gradient_accumulation_steps=<span class="number">1</span> \</span><br><span class="line">    --line_by_line \</span><br><span class="line">    --overwrite_output_dir</span><br></pre></td></tr></table></figure>
<h2 id="4-2-Load-and-Manually-Test-Model"><a href="#4-2-Load-and-Manually-Test-Model" class="headerlink" title="4.2 Load and Manually Test Model"></a>4.2 Load and Manually Test Model</h2><p>You can play around with the model, generating utterances for different intents. See how the parameters top_k and top_p influence the result.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> GPT2Tokenizer, TFGPT2LMHeadModel</span><br><span class="line"></span><br><span class="line">tokenizer = GPT2Tokenizer.from_pretrained(<span class="string">&quot;gpt2-medium&quot;</span>)</span><br><span class="line">model = TFGPT2LMHeadModel.from_pretrained(</span><br><span class="line">    <span class="string">&#x27;.//content//transformers//output//&#x27;</span>, </span><br><span class="line">    pad_token_id=tokenizer.eos_token_id, from_pt=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><strong>Top k sampling</strong> means sorting by probability and zero-ing out the probabilities for anything below the k’th token. It appears to improve quality by removing the tail and making it less likely to go off topic. But in some cases, there really are many words we could sample from reasonably (broad distribution below), and in some cases there aren’t (narrow distribution below).</p>
<p>To address this problem, the authors propose <strong>top p sampling</strong>, aka nucleus sampling, in which we compute the cumulative distribution and cut off as soon as the CDF exceeds P. In the broad distribution example above, it may take the top 100 tokens to exceed top_p = .9. In the narrow distribution, we may already exceed top_p = .9 with just “hot” and “warm” in our sample distribution. In this way, we still avoid sampling egregiously wrong tokens, but preserve variety when the highest scoring tokens have low confidence.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">input_ids = tokenizer.encode(<span class="string">&#x27;i m trying to&#x27;</span>, return_tensors=<span class="string">&#x27;tf&#x27;</span>)</span><br><span class="line">sample_outputs = model.generate(</span><br><span class="line">    input_ids,</span><br><span class="line">    do_sample=<span class="literal">True</span>, </span><br><span class="line">    max_length=<span class="number">50</span>, </span><br><span class="line">    top_k=<span class="number">10</span>,</span><br><span class="line">    top_p=<span class="number">0.9</span>, </span><br><span class="line">    num_return_sequences=<span class="number">10</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Output:\n&quot;</span> + <span class="number">100</span> * <span class="string">&#x27;-&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i, sample_output <span class="keyword">in</span> <span class="built_in">enumerate</span>(sample_outputs):</span><br><span class="line">  print(<span class="string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i, tokenizer.decode(sample_output, skip_special_tokens=<span class="literal">True</span>)))</span><br></pre></td></tr></table></figure>
<h2 id="Output"><a href="#Output" class="headerlink" title="Output:"></a>Output:</h2><blockquote>
<p>0: i m trying to get a list of all the words in the wordlist and their synonyms. it s a wordlist of about 10k words. i m trying to do a word frequency plot. the word frequency plot shows that the frequency of<br>1: i m trying to find out if there are any books on bitcoin cash which are free for anyone to download. the author of the book, jr. b. lang, is a bitcoin cash expert and has been quoted in many publications as saying that<br>2: i m trying to find a way to get my iphone from to my apple apple tv via usb. my iphone is 3rd gen and apple tv 2nd gen.<br>3: i m trying to determine if there are two sets of rules for a particular problem that can be applied to any other problem. one set of rules is for discrete cases and the second set is for continuous cases.&#xd;<br>4: i m trying to understand how a node can be a node in a dapp.&#xd;&#xa;i m trying to understand how a node can be a node in a dapp.&#xd;<br>5: i m trying to do a pulldown on a website with a template.i m using jquery.getElementsByTagName(‘meta’) and the following output<br>6: i m trying to determine the best way to store my bitcoin. my bitcoin is stored on my master wallet. however, i want to add the bch address from my wallet to my bitcoin. my master wallet only has the private key of the wallet<br>7: i m trying to find a way to show the number of lines in the code of a function. i m using the following code snippet from the os x man page: &#xd;<br>8: i m trying to find the code for my samsung galaxy s3. the s3 is a s1 with an ikon gsm  camera. the camera is a 1.5m  lens. it also has the moto g<br>9: i m trying to figure out a way to find out the time and date of the most recent call. i m using the time-to-call function from the samsung s go-pro app, but the function does not work on my device</p>
</blockquote>
<h2 id="4-3-Prepare-Model-for-Download"><a href="#4-3-Prepare-Model-for-Download" class="headerlink" title="4.3 Prepare Model for Download"></a>4.3 Prepare Model for Download</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!<span class="built_in">zip</span> -r -X gpt-2_tuned.<span class="built_in">zip</span> .//content//transformers//output</span><br></pre></td></tr></table></figure>
<blockquote>
<p>  adding: /content//transformers//output/ (stored 0%)<br>  adding: /content//transformers//output/tokenizer_config.json (deflated 37%)<br>  adding: /content//transformers//output/vocab.json (deflated 59%)<br>  adding: /content//transformers//output/config.json (deflated 51%)<br>  adding: /content//transformers//output/training_args.bin (deflated 44%)<br>  adding: /content//transformers//output/merges.txt (deflated 53%)<br>  adding: /content//transformers//output/special_tokens_map.json (deflated 52%)<br>  adding: /content//transformers//output/checkpoint-500/ (stored 0%)<br>  adding: /content//transformers//output/checkpoint-500/optimizer.pt (deflated 9%)<br>  adding: /content//transformers//output/checkpoint-500/tokenizer_config.json (deflated 37%)<br>  adding: /content//transformers//output/checkpoint-500/vocab.json (deflated 59%)<br>  adding: /content//transformers//output/checkpoint-500/config.json (deflated 51%)<br>  adding: /content//transformers//output/checkpoint-500/training_args.bin (deflated 44%)<br>  adding: /content//transformers//output/checkpoint-500/merges.txt (deflated 53%)<br>  adding: /content//transformers//output/checkpoint-500/special_tokens_map.json (deflated 52%)<br>  adding: /content//transformers//output/checkpoint-500/scheduler.pt (deflated 49%)<br>  adding: /content//transformers//output/checkpoint-500/pytorch_model.bin (deflated 9%)<br>  adding: /content//transformers//output/pytorch_model.bin (deflated 9%)</p>
</blockquote>
<h1 id="Step-5-Generate-and-Filter-New-Utterances"><a href="#Step-5-Generate-and-Filter-New-Utterances" class="headerlink" title="Step 5: Generate and Filter New Utterances"></a>Step 5: Generate and Filter New Utterances</h1><p><strong>We now generate the new utterances for all intents. To have a sufficiently large sample that we can choose the best utterances from, we generate 200 per intent.</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">NUMBER_OF_GENERATED_UTTERANCES_PER_INTENT = <span class="number">200</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_utterances_df</span>(<span class="params">n_generated, tokenizer, model, intent</span>):</span></span><br><span class="line">    input_ids = tokenizer.encode(intent + <span class="string">&#x27;,&#x27;</span>, return_tensors=<span class="string">&#x27;tf&#x27;</span>)</span><br><span class="line">    sample_outputs = model.generate(</span><br><span class="line">        input_ids,</span><br><span class="line">        do_sample=<span class="literal">True</span>, </span><br><span class="line">        max_length=<span class="number">50</span>, </span><br><span class="line">        top_k=n_generated, </span><br><span class="line">        top_p=<span class="number">0.92</span>, </span><br><span class="line">        num_return_sequences=n_generated)</span><br><span class="line"></span><br><span class="line">    list_of_intent_and_utterances = [(</span><br><span class="line">        intent, tokenizer.decode(sample_output, skip_special_tokens=<span class="literal">True</span>)[<span class="built_in">len</span>(intent)+<span class="number">1</span>:]) </span><br><span class="line">        <span class="keyword">for</span> sample_output <span class="keyword">in</span> sample_outputs]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> pandas.DataFrame(list_of_intent_and_utterances, columns=[<span class="string">&#x27;intent&#x27;</span>, <span class="string">&#x27;utterance&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p><strong>Generate the result by calling the function above:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">labels = data_train[<span class="string">&quot;Label&quot;</span>].unique()</span><br><span class="line"></span><br><span class="line">generated_utterances_df = pandas.DataFrame(columns=[<span class="string">&#x27;Outcome&#x27;</span>, <span class="string">&#x27;Text&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">    print(<span class="string">&quot;Generating for intent &quot;</span> + label)</span><br><span class="line">    utterances_for_intent_df = generate_utterances_df(</span><br><span class="line">        NUMBER_OF_GENERATED_UTTERANCES_PER_INTENT, tokenizer, model, label)</span><br><span class="line">    generated_utterances_df = generated_utterances_df.append(utterances_for_intent_df)</span><br></pre></td></tr></table></figure>
<p><strong>Save file:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">generated_utterances_df.to_csv(<span class="string">&quot;generated.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h2 id="5-1-Train-BERT-Classifier-with-Augmented-Dataset"><a href="#5-1-Train-BERT-Classifier-with-Augmented-Dataset" class="headerlink" title="5.1 Train BERT Classifier with Augmented Dataset"></a>5.1 Train BERT Classifier with Augmented Dataset</h2><p>After a while the data is generated, and we can have a closer look at it. First, we use our old distilBERT classifier to predict the intent for all generated utterances. We also keep track of the prediction probability indicating the level of confidence of each individual prediction made by our model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">generated_data = generated_utterances_df.assign(</span><br><span class="line">    utterance=[utterance.replace(<span class="string">&#x27;!&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">for</span> utterance <span class="keyword">in</span> generated_utterances_df[<span class="string">&#x27;utterance&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">predictions_for_generated = np.array(predictor.predict(</span><br><span class="line">    generated_data[<span class="string">&#x27;utterance&#x27;</span>].tolist(), </span><br><span class="line">    return_proba=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">proba_for_predictions_for_gen = predictor.predict(</span><br><span class="line">    generated_data[<span class="string">&#x27;utterance&#x27;</span>].tolist(), </span><br><span class="line">    return_proba=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">predicted_proba = np.array([</span><br><span class="line">    <span class="built_in">max</span>(probas) <span class="keyword">for</span> probas <span class="keyword">in</span> proba_for_predictions_for_gen])</span><br><span class="line"></span><br><span class="line">generated_data_predicted = pandas.DataFrame(&#123;</span><br><span class="line">    <span class="string">&quot;intent&quot;</span>: generated_data[<span class="string">&#x27;intent&#x27;</span>],</span><br><span class="line">    <span class="string">&quot;utterance&quot;</span>: generated_data[<span class="string">&#x27;utterance&#x27;</span>],</span><br><span class="line">    <span class="string">&quot;predicted_intent&quot;</span>: predictions_for_generated,</span><br><span class="line">    <span class="string">&quot;prediction_proba&quot;</span>: predicted_proba&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>Let’s have a look at some of the utterances for which the intent used for generation does not match the predicted intent.</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">generated_data_predicted[generated_data_predicted[<span class="string">&#x27;intent&#x27;</span>] != </span><br><span class="line">                         generated_data_predicted[<span class="string">&#x27;predicted_intent&#x27;</span>]].head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right"></th>
<th style="text-align:right">intent</th>
<th style="text-align:right">utterance</th>
<th style="text-align:right">predicted_intent</th>
<th>prediction_proba</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">why is there a special category called <code>coset</code>…</td>
<td style="text-align:right"><strong>label</strong>14</td>
<td>0.602601</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">how can i set up qgis for different operating …</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.918635</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">is there a minimum required work weekly for eu…</td>
<td style="text-align:right"><strong>label</strong>6</td>
<td>0.835881</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">who was ryan about the arcania</td>
<td style="text-align:right"><strong>label</strong>10</td>
<td>0.564748</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">example of combining points data</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.927397</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">how can i switch between my the clock/utc-rpi …</td>
<td style="text-align:right"><strong>label</strong>3</td>
<td>0.430493</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">which mlb agent is responsible for taxonomy of…</td>
<td style="text-align:right"><strong>label</strong>11</td>
<td>0.572228</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">how can i prove that two points are continuous…</td>
<td style="text-align:right"><strong>label</strong>14</td>
<td>0.950781</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">has any information been released on the first…</td>
<td style="text-align:right"><strong>label</strong>11</td>
<td>0.387223</td>
</tr>
<tr>
<td style="text-align:right">13</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">using a syringe as a syringe launch vehicle</td>
<td style="text-align:right"><strong>label</strong>4</td>
<td>0.936194</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">what did the imac do to quinlan</td>
<td style="text-align:right"><strong>label</strong>10</td>
<td>0.685168</td>
</tr>
<tr>
<td style="text-align:right">16</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">difference in error rate of arcgis 9.4.1 &amp;…</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.838147</td>
</tr>
<tr>
<td style="text-align:right">17</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">distance traveled along a polyline during a run</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.808309</td>
</tr>
<tr>
<td style="text-align:right">19</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">is the the on/off switch located on the left o…</td>
<td style="text-align:right"><strong>label</strong>5</td>
<td>0.552347</td>
</tr>
<tr>
<td style="text-align:right">20</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">select a point on a polyline of length n</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.873443</td>
</tr>
<tr>
<td style="text-align:right">22</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">i am having trouble with get_page_info on page…</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.609694</td>
</tr>
<tr>
<td style="text-align:right">23</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">find the cheapest arcmap api and gps data for …</td>
<td style="text-align:right"><strong>label</strong>13</td>
<td>0.916163</td>
</tr>
<tr>
<td style="text-align:right">24</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">why does georgia use mars to colonize terra</td>
<td style="text-align:right"><strong>label</strong>4</td>
<td>0.940666</td>
</tr>
<tr>
<td style="text-align:right">25</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">are philippino air travelers required to provi…</td>
<td style="text-align:right"><strong>label</strong>1</td>
<td>0.959981</td>
</tr>
<tr>
<td style="text-align:right">26</td>
<td style="text-align:right"><strong>label</strong>12</td>
<td style="text-align:right">transactions in bip38</td>
<td style="text-align:right"><strong>label</strong>11</td>
<td>0.938041</td>
</tr>
</tbody>
</table>
</div>
<p>We can see that in some cases the prediction is clearly wrong. However, there are also cases where the prediction matches the utterance, but doesn’t match the intent used for generation. This indicates that our GPT-2 model is not perfect as it doesn’t generate matching utterances for an intent all the time.</p>
<p><strong>To stop from training our classifier with corrupt data, we drop all utterances for which the basic intent does not match the predicted intent. For those with matching instances, we only keep the ones with the highest prediction probability scores.</strong></p>
<h2 id="5-2-Filter-Generated-Utterances"><a href="#5-2-Filter-Generated-Utterances" class="headerlink" title="5.2 Filter Generated Utterances"></a>5.2 Filter Generated Utterances</h2><p>Filter utterances with old classifier when prediction matches:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">correctly_predicted_data = generated_data_predicted[</span><br><span class="line">    generated_data_predicted[<span class="string">&#x27;intent&#x27;</span>] == generated_data_predicted[<span class="string">&#x27;predicted_intent&#x27;</span>]]</span><br><span class="line">correctly_predicted_data.groupby(<span class="string">&quot;intent&quot;</span>).count()</span><br></pre></td></tr></table></figure>
<p>Check for the number of unique utterances per intent:</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">correctly_predicted_data.drop_duplicates(</span><br><span class="line">    <span class="attribute">subset</span>=<span class="string">&#x27;utterance&#x27;</span>, <span class="attribute">keep</span>=<span class="string">&#x27;first&#x27;</span>).sort_values(</span><br><span class="line">    by=[<span class="string">&#x27;intent&#x27;</span>, <span class="string">&#x27;prediction_proba&#x27;</span>], ascending=[<span class="literal">True</span>, <span class="literal">False</span>]).drop_duplicates(</span><br><span class="line">    <span class="attribute">keep</span>=<span class="string">&#x27;first&#x27;</span>).groupby(&#x27;intent&#x27;).count()</span><br></pre></td></tr></table></figure>
<p>Take TOP_N predictions per intent according to probability and drop duplicated</p>
<p>We can see that for each intent, there are at least 35 mutually distinct utterances. To keep a balanced data set, we pick the top 30 utterances per intent according to the prediction probability.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TOP_N = <span class="number">30</span></span><br><span class="line">top_predictions_per_intent = correctly_predicted_data.drop_duplicates(</span><br><span class="line">    subset=<span class="string">&#x27;utterance&#x27;</span>, keep=<span class="string">&#x27;first&#x27;</span>).sort_values(</span><br><span class="line">    by=[<span class="string">&#x27;intent&#x27;</span>, <span class="string">&#x27;prediction_proba&#x27;</span>], ascending=[<span class="literal">True</span>, <span class="literal">False</span>]).drop_duplicates(</span><br><span class="line">    keep=<span class="string">&#x27;first&#x27;</span>).groupby(<span class="string">&#x27;intent&#x27;</span>).head(TOP_N)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top_predictions_per_intent</span><br></pre></td></tr></table></figure>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right"></th>
<th style="text-align:right">intent</th>
<th style="text-align:right">utterance</th>
<th style="text-align:right">predicted_intent</th>
<th>prediction_proba</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">103</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td style="text-align:right">adding jquery files from within a wordpress theme</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.810196</td>
</tr>
<tr>
<td style="text-align:right">66</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td style="text-align:right">formatting wordpress content</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.808586</td>
</tr>
<tr>
<td style="text-align:right">131</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td style="text-align:right">add.php to front page of wordpress</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.807943</td>
</tr>
<tr>
<td style="text-align:right">177</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td style="text-align:right">adding wordpress in post_meta subcategory</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.804899</td>
</tr>
<tr>
<td style="text-align:right">51</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td style="text-align:right">is there a way to change how views are display…</td>
<td style="text-align:right"><strong>label</strong>0</td>
<td>0.801144</td>
</tr>
<tr>
<td style="text-align:right">…</td>
<td style="text-align:right">…</td>
<td style="text-align:right">…</td>
<td style="text-align:right">…</td>
<td>…</td>
</tr>
<tr>
<td style="text-align:right">36</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td style="text-align:right">new player</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td>0.815141</td>
</tr>
<tr>
<td style="text-align:right">147</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td style="text-align:right">is there a way to get a different card with ea…</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td>0.772208</td>
</tr>
<tr>
<td style="text-align:right">117</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td style="text-align:right">how do i recover my lost data</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td>0.768557</td>
</tr>
<tr>
<td style="text-align:right">49</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td style="text-align:right">i need to save my first pakistani boy in dlc 2…</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td>0.757511</td>
</tr>
<tr>
<td style="text-align:right">15</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td style="text-align:right">how can i bypass game engine antiophthalmic fa…</td>
<td style="text-align:right"><strong>label</strong>9</td>
<td>0.738432</td>
</tr>
</tbody>
</table>
</div>
<h1 id="Step-6-Train-the-Intent-Classifier-with-Augmented-Data"><a href="#Step-6-Train-the-Intent-Classifier-with-Augmented-Data" class="headerlink" title="Step 6: Train the Intent Classifier with Augmented Data"></a>Step 6: Train the Intent Classifier with Augmented Data</h1><h2 id="6-1-Combine-Old-and-Augmented-Data"><a href="#6-1-Combine-Old-and-Augmented-Data" class="headerlink" title="6.1 Combine Old and Augmented Data"></a>6.1 Combine Old and Augmented Data</h2><p>We now combine the generated data with the initial training data and split the enriched data set intotraining and validation data.</p>
<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">data_train_aug = data_train.append(top_predictions_per_intent[[<span class="string">&#x27;intent&#x27;</span>, <span class="string">&#x27;utterance&#x27;</span>]].rename(</span><br><span class="line">    columns=&#123;<span class="string">&#x27;intent&#x27;</span>:<span class="string">&#x27;Label&#x27;</span>, <span class="string">&#x27;utterance&#x27;</span>:<span class="string">&#x27;Text&#x27;</span>&#125;), ignore_index=<span class="symbol">True</span>)</span><br><span class="line">data_train_aug</span><br><span class="line"></span><br><span class="line">labels = data_train_aug[<span class="string">&#x27;Label&#x27;</span>].unique()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="symbol">X_train_aug</span>, <span class="symbol">X_valid_aug</span>, <span class="symbol">X_test_aug</span> = [], [], []</span><br><span class="line">y_train_aug, y_valid_aug, y_test_aug = [], [], []</span><br><span class="line">for label in labels:</span><br><span class="line">    intent_X_train, intent_X_valid, intent_y_train, intent_y_valid = train_test_split(</span><br><span class="line">        data_train[data_train[<span class="string">&#x27;Label&#x27;</span>] == label][<span class="string">&#x27;Text&#x27;</span>],</span><br><span class="line">        data_train[data_train[<span class="string">&#x27;Label&#x27;</span>] == label][<span class="string">&#x27;Label&#x27;</span>],</span><br><span class="line">        train_size=<span class="number">0.8</span>,</span><br><span class="line">        random_state=<span class="number">43</span>)</span><br><span class="line">    intent_X_valid, intent_X_test, intent_y_valid, intent_y_test = train_test_split(</span><br><span class="line">        intent_X_valid, intent_y_valid,</span><br><span class="line">        train_size=<span class="number">0.5</span>,</span><br><span class="line">        random_state=<span class="number">43</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="symbol">X_train_aug</span>.extend(intent_X_train)</span><br><span class="line">    <span class="symbol">X_valid_aug</span>.extend(intent_X_valid)</span><br><span class="line">    <span class="symbol">X_test_aug</span>.extend(intent_X_test)</span><br><span class="line">    y_train_aug.extend(intent_y_train)</span><br><span class="line">    y_valid_aug.extend(intent_y_valid)</span><br><span class="line">    y_test_aug.extend(intent_y_test)</span><br></pre></td></tr></table></figure>
<h2 id="6-2-Initialise-Augmented-Model-and-Learner"><a href="#6-2-Initialise-Augmented-Model-and-Learner" class="headerlink" title="6.2 Initialise Augmented Model and Learner"></a>6.2 Initialise Augmented Model and Learner</h2><p>Now it’s time to train our new intent classification model. The code is like the one above:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">distil_bert_augmented = text.Transformer(<span class="string">&#x27;distilbert-base-cased&#x27;</span>, </span><br><span class="line">                                         maxlen=<span class="number">50</span>, </span><br><span class="line">                                         classes=intents)</span><br></pre></td></tr></table></figure>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">processed_train_aug</span> = distil_bert_augmented.preprocess_train(</span><br><span class="line">    X_train_aug, y_train_aug)</span><br><span class="line"><span class="attr">processed_test_aug</span> = distil_bert_augmented.preprocess_test(</span><br><span class="line">    X_valid_aug, y_valid_aug)</span><br><span class="line">    </span><br><span class="line"><span class="attr">model_aug</span> = distil_bert_augmented.get_classifier()</span><br><span class="line"><span class="attr">learner_aug</span> = ktrain.get_learner(</span><br><span class="line">    model_aug, </span><br><span class="line">    <span class="attr">train_data=processed_train_aug,</span> </span><br><span class="line">    <span class="attr">val_data=processed_test_aug,</span> </span><br><span class="line">    <span class="attr">batch_size=50)</span></span><br></pre></td></tr></table></figure>
<h2 id="6-3-Train-Classifier"><a href="#6-3-Train-Classifier" class="headerlink" title="6.3 Train Classifier"></a>6.3 Train Classifier</h2><p>Train classifier for given learning rate and number of epochs.</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">N_TRAINING_EPOCHS_AUGMENTED</span> = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">learner_aug</span>.fit_onecycle(<span class="number">5</span>e-<span class="number">5</span>, N_TRAINING_EPOCHS_AUGMENTED)</span><br></pre></td></tr></table></figure>
<h2 id="6-4-Evaluate-Trained-Predictor"><a href="#6-4-Evaluate-Trained-Predictor" class="headerlink" title="6.4 Evaluate Trained Predictor"></a>6.4 Evaluate Trained Predictor</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">predictor_aug = ktrain.get_predictor(</span><br><span class="line">    learner_aug.model, </span><br><span class="line">    preproc=distil_bert_augmented)</span><br><span class="line"></span><br><span class="line">predictions_aug = predictor_aug.predict(X_test_aug)</span><br><span class="line"></span><br><span class="line">np_test_intents = np.array(y_test_aug)</span><br><span class="line">np_predictions_aug = np.array(predictions_aug)</span><br><span class="line"></span><br><span class="line">result_aug = (np_test_intents == np_predictions_aug)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Accuracy: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(result_aug.<span class="built_in">sum</span>()/<span class="built_in">len</span>(result_aug)*<span class="number">100</span>))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Accuracy: 87.85%</p>
</blockquote>
<h2 id="6-5-Prepare-Model-for-Download"><a href="#6-5-Prepare-Model-for-Download" class="headerlink" title="6.5 Prepare Model for Download"></a>6.5 Prepare Model for Download</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">predictor.save(<span class="string">&#x27;models/augmented/_distilbert_aug_&#123;&#125;epochs_&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">    N_TRAINING_EPOCHS_AUGMENTED, </span><br><span class="line">    datetime.datetime.now().strftime(<span class="string">&quot;%Y-%m-%d-%H-%M-%S-%f&quot;</span>)))</span><br><span class="line"></span><br><span class="line">!<span class="built_in">zip</span> -r -X distilbert_augmented.<span class="built_in">zip</span> models/augmented</span><br></pre></td></tr></table></figure>
<blockquote>
<p>adding: models/augmented/ (stored 0%)<br>adding: models/augmented/_distilbert_aug_5epochs_2021-04-01-15-13-40-763970/ (stored 0%)<br>adding: models/augmented/_distilbert_aug_5epochs_2021-04-01-15-13-40-763970/config.json (deflated 61%)<br>adding: models/augmented/_distilbert_aug_5epochs_2021-04-01-15-13-40-763970/tf_model.h5 (deflated 8%)<br>adding: models/augmented/_distilbert_aug_5epochs_2021-04-01-15-13-40-763970/tf_model.preproc (deflated 55%)</p>
</blockquote>
<h1 id="LAMBADA-AI-Summary"><a href="#LAMBADA-AI-Summary" class="headerlink" title="LAMBADA AI: Summary"></a>LAMBADA AI: Summary</h1><p><strong>We employed the LAMBADA method to augment data used for Natural Language Understanding (NLU) tasks. We trained a GPT-2 model to generate new training utterances and utilized them as training data for our intent classification model (DistilBERT). The performance of the intent classification model improved by at least 4% in each of our tests.</strong></p>
<p>Additionally, we saw that high-level libraries such as KTrain and Huggingface Transformers help to reduce the complexity of applying state-of-the-art transformer models for Natural Language Generation (NLG) and other Natural Language Processing (NLP) tasks such as classification and make these approaches broadly applicable.</p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.steadforce.com/blog/lambada-method-how-to-use-data-augmentation-in-nlu">LAMBADA Method: How to use Data Augmentation in NLU?</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>


<script src="/Blog/js/vdonate.js"></script>

<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: 'Donate', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/WeChanQR.png',
  alipayImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/AliPayQR.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Haojun(Vincent) Gao</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/" target="_blank" title="LAMBADA Method: How to use Data Augmentation in NLU?">http://vincentgaohj.github.io/Blog/2021/10/30/LAMBADA-Method-How-to-use-Data-Augmentation-in-NLU/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/BERT/" rel="tag">BERT</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/GPT-2/" rel="tag">GPT-2</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Machine-Learning/" rel="tag">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Natural-Language-Processing/" rel="tag">Natural Language Processing</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Netural-Language-Generation/" rel="tag">Netural Language Generation</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/Blog/2021/10/26/Not-Enough-Data-Deep-Learning-to-the-Rescue/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Not Enough Data? Deep Learning to the Rescue!</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-1-Preparation"><span class="nav-number">1.</span> <span class="nav-text">Step 1: Preparation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-2-Load-Data"><span class="nav-number">2.</span> <span class="nav-text">Step 2: Load Data</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-3-Training-the-Initial-Intent-Classifier-BERT"><span class="nav-number">3.</span> <span class="nav-text">Step 3: Training the Initial Intent Classifier (BERT)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Initialize-model-and-learner"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Initialize model and learner</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Train-classifier"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 Train classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-Evaluate-trained-predictor"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 Evaluate trained predictor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-Prepare-model-for-download"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 Prepare model for download</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-4-Fine-tune-GPT-2-to-generate-utterances"><span class="nav-number">4.</span> <span class="nav-text">Step 4:  Fine-tune GPT-2 to generate utterances</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-Fine-tune-GPT-2"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 Fine-tune GPT-2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-Load-and-Manually-Test-Model"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 Load and Manually Test Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Output"><span class="nav-number">4.3.</span> <span class="nav-text">Output:</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-Prepare-Model-for-Download"><span class="nav-number">4.4.</span> <span class="nav-text">4.3 Prepare Model for Download</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-5-Generate-and-Filter-New-Utterances"><span class="nav-number">5.</span> <span class="nav-text">Step 5: Generate and Filter New Utterances</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-Train-BERT-Classifier-with-Augmented-Dataset"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 Train BERT Classifier with Augmented Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Filter-Generated-Utterances"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 Filter Generated Utterances</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Step-6-Train-the-Intent-Classifier-with-Augmented-Data"><span class="nav-number">6.</span> <span class="nav-text">Step 6: Train the Intent Classifier with Augmented Data</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-Combine-Old-and-Augmented-Data"><span class="nav-number">6.1.</span> <span class="nav-text">6.1 Combine Old and Augmented Data</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-Initialise-Augmented-Model-and-Learner"><span class="nav-number">6.2.</span> <span class="nav-text">6.2 Initialise Augmented Model and Learner</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-Train-Classifier"><span class="nav-number">6.3.</span> <span class="nav-text">6.3 Train Classifier</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-Evaluate-Trained-Predictor"><span class="nav-number">6.4.</span> <span class="nav-text">6.4 Evaluate Trained Predictor</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-Prepare-Model-for-Download"><span class="nav-number">6.5.</span> <span class="nav-text">6.5 Prepare Model for Download</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#LAMBADA-AI-Summary"><span class="nav-number">7.</span> <span class="nav-text">LAMBADA AI: Summary</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Reference"><span class="nav-number">8.</span> <span class="nav-text">Reference</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2021 Gao Haojun All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>



<!-- 2017.6.11，masikkk新增，加载本地Google Prettify 代码高亮js代码 -->

<!--
<script src="/Blog/js/prettify.js"></script>
-->

<!-- 2017.6.11，masikkk新增，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(window).load(function(){})是在页面所有元素(包括所有css,js,图片,Flash等)加载完毕后执行
<script type="text/javascript">
$(window).load(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->
<!-- 2017.7.1，masikkk添加，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(document).ready(function(){})是当页面的标准DOM元素被解析成DOM树后就执行 -->

<!--
<script type="text/javascript">
$(document).ready(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->

<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>



    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/Blog/" class="mobile-nav-link">Home</a>
  
    <a href="/Blog/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/Blog/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/Blog/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/Blog/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/Blog/fancybox/jquery.fancybox.css">

  
<script src="/Blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/Blog/js/scripts.js"></script>





  
<script src="/Blog/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Gao Haojun
          </div>
          <div class="panel-body">
            Copyright © 2021 Haojun(Vincent) Gao All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
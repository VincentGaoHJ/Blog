<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>the design principle of pytorch architecture | Gao Haojun</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="PyTorchDeep Learning" />
  
  
  
  
  <meta name="description" content="The article introduces the detailed principles that drive the implementation of PyTorch and how these principles are reflected in the PyTorch architecture.">
<meta property="og:type" content="article">
<meta property="og:title" content="The Design Principle of PyTorch Architecture">
<meta property="og:url" content="http://vincentgaohj.github.io/Blog/2021/01/17/The-Design-Principle-of-Pytorch-Architecture/index.html">
<meta property="og:site_name" content="Gao Haojun">
<meta property="og:description" content="The article introduces the detailed principles that drive the implementation of PyTorch and how these principles are reflected in the PyTorch architecture.">
<meta property="og:locale">
<meta property="og:image" content="https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/pytorch-logo-dark.png?raw=true">
<meta property="og:image" content="https://pic2.zhimg.com/v2-35c1855d415cf6958566483e1c607693_1440w.jpg?source=172ae18b">
<meta property="article:published_time" content="2021-01-17T01:41:20.000Z">
<meta property="article:modified_time" content="2021-01-18T04:08:02.392Z">
<meta property="article:author" content="Haojun(Vincent) Gao">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/pytorch-logo-dark.png?raw=true">
  
    <link rel="alternate" href="/atom.xml" title="Gao Haojun" type="application/atom+xml">
  

  

  <link rel="icon" href="/Blog/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/Blog/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt; src:url("css/fonts/FuturaPTBold.otf") format("woff");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt-light; src:url("css/fonts/FuturaPTBook.otf") format("woff");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt-italic; src:url("css/fonts/FuturaPTBookOblique.otf") format("woff");font-weight:400;font-style:italic;}
}

  </style>
  
<link rel="stylesheet" href="/Blog/css/style.css">


  
<script src="/Blog/js/jquery-3.1.1.min.js"></script>

  
<script src="/Blog/js/bootstrap.js"></script>


  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/Blog/css/bootstrap.css" >

  

  
  

  
    
<link rel="stylesheet" href="/Blog/css/dialog.css">

  

  

  
    <link rel="stylesheet" href="/Blog/css/header-post.css" >
  

  
  
  
    <link rel="stylesheet" href="/Blog/css/vdonate.css" >
  

<meta name="generator" content="Hexo 5.2.0"></head>



  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/Blog/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/Blog/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/Blog/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/Blog/',
        CONTENT_URL: '/Blog/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/Blog/js/insight.js"></script>


</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-The-Design-Principle-of-Pytorch-Architecture" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      The Design Principle of PyTorch Architecture
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/Blog/2021/01/17/The-Design-Principle-of-Pytorch-Architecture/" class="article-date">
	  <time datetime="2021-01-17T01:41:20.000Z" itemprop="datePublished">2021-01-17</time>
	</a>

      
    <a class="article-category-link" href="/Blog/categories/Deep-Learning/">Deep Learning</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

      

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>The article introduces the detailed principles that drive the implementation of PyTorch and how these principles are reflected in the PyTorch architecture.</p>
<p><img src="https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/pytorch-logo-dark.png?raw=true" alt=""></p>
<a id="more"></a>
<h2 id="Design-principles"><a href="#Design-principles" class="headerlink" title="Design principles"></a>Design principles</h2><p>PyTorch’s success stems from weaving previous ideas into a design that balances speed and ease of use. There are four main principles behind our choices:</p>
<p><strong>Be Pythonic:</strong> Data scientists are familiar with the Python language, its programming model, and it stools. </p>
<p><strong>Put researchers first:</strong> PyTorch strives to make writing models, data loaders, and optimizers as easy and productive as possible.  </p>
<p><strong>Provide pragmatic performance:</strong> To be useful, PyTorch needs to deliver compelling performance,although not at the expense of simplicity and ease of use. </p>
<p><strong>Worse is better:</strong> Given a fixed amount of engineering resources, and all else being equal, the time saved by keeping the internal implementation of PyTorch simple can be used to implement additional features, adapt to new situations, and keep up with the fast pace of progress in the field of AI. Therefore it is better to have a simple but slightly incomplete solution than a comprehensive but complex and hard to maintain design.</p>
<h2 id="Usability-Centric-Design"><a href="#Usability-Centric-Design" class="headerlink" title="Usability Centric Design"></a>Usability Centric Design</h2><h3 id="Deep-learning-models-are-just-Python-programs"><a href="#Deep-learning-models-are-just-Python-programs" class="headerlink" title="Deep learning models are just Python programs"></a>Deep learning models are just Python programs</h3><p>The neural networks themselves evolved rapidly from simple sequences of feed forward layers into incredibly varied numerical programs often composed of many loops and recursive functions. To support this growing complexity, PyTorch foregos the potential benefits of a graph-meta programming based approach to preserve the imperative programming model of Python.  </p>
<p><strong>PyTorch extends this to all aspects of deep learning workflows.</strong> Defining layers, composing models, loading data, running optimizers, and parallelizing the training process are all expressed using the familiar concepts developed for general purpose programming. <strong>This solution ensures that any new potential neural network architecture can be easily implemented with PyTorch.</strong> </p>
<h3 id="Interoperability-and-extensibility"><a href="#Interoperability-and-extensibility" class="headerlink" title="Interoperability and extensibility"></a>Interoperability and extensibility</h3><p>Easy and efficient interoperability is one of the top priorities for PyTorch because it opens the possibility to leverage the rich ecosystem of Python libraries as part of user programs. <strong>Hence, PyTorch allows for bidirectional exchange of data with external libraries.</strong></p>
<ul>
<li>For example, it provides a mechanism to convert between NumPy arrays and PyTorch tensors using the <code>torch.from_numpy()</code> function and <code>.numpy()</code> tensor method.</li>
<li>Similar functionality is also available to exchange data stored using the <a target="_blank" rel="noopener" href="https://github.com/dmlc/dlpack">DLPack</a> format. </li>
</ul>
<h3 id="Automatic-differentiation"><a href="#Automatic-differentiation" class="headerlink" title="Automatic differentiation"></a>Automatic differentiation</h3><p><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=BJJsrmfCZ">In its current implementation, PyTorch performs reverse-mode automatic differentiation, which computes the gradient of a scalar output with respect to a multivariate input.</a> <strong>Differentiating functions with more outputs than inputs is more efficiently executed using forward-mode automatic differentiation, but this use case is less common for machine learning applications.</strong></p>
<hr>
<h2 id="Common-Code-Snippets"><a href="#Common-Code-Snippets" class="headerlink" title="Common Code Snippets"></a>Common Code Snippets</h2><h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PyTorch version</span></span><br><span class="line">torch.__version__                           <span class="comment"># PyTorch version</span></span><br><span class="line">conda update pytorch torchvision -c pytorch <span class="comment"># Update PyTorch</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># CUDA</span></span><br><span class="line">torch.version.cuda                          <span class="comment"># Check corresponding CUDA Version</span></span><br><span class="line">torch.cuda.is_available()                   <span class="comment"># Check whether there is CUDA support</span></span><br><span class="line">torch.cuda.empty_cache()                    <span class="comment"># Manually release GPU storage after stops running</span></span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span> python train.py    <span class="comment"># Run on a specific GPU: Command Line</span></span><br><span class="line">os.environ[<span class="string">&#x27;CUDA_VISIBLE_DEVICES&#x27;</span>] = <span class="string">&#x27;0,1&#x27;</span>  <span class="comment"># Run on a specific GPU: Code</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># cuDNN</span></span><br><span class="line">torch.backends.cudnn.version()              <span class="comment"># Corresponding cuDNN version</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">True</span>       <span class="comment"># Increase the speed, but calculation are slightly different due to the randomness.</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span>   <span class="comment"># Avoid this randomness/fluctuation of results</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GPU type</span></span><br><span class="line">torch.cuda.get_device_name(<span class="number">0</span>)               <span class="comment"># GPU type</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Fixed random seed</span></span><br><span class="line">torch.manual_seed(<span class="number">0</span>)</span><br><span class="line">torch.cuda.manual_seed_all(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Tensor Information</span></span><br><span class="line">tensor.<span class="built_in">type</span>()                                       <span class="comment"># Data type</span></span><br><span class="line">tensor.size()                                       <span class="comment"># Shape of the tensor. It is a subclass of Python tuple</span></span><br><span class="line">tensor.dim()                                        <span class="comment"># Number of dimensions.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Type convertions (Float in PyTorch is much faster than double.)</span></span><br><span class="line">torch.set_default_tensor_type(torch.FloatTensor)    <span class="comment"># Set default tensor type.</span></span><br><span class="line">tensor = tensor.cuda()</span><br><span class="line">tensor = tensor.cpu()</span><br><span class="line">tensor = tensor.<span class="built_in">float</span>()</span><br><span class="line">tensor = tensor.long()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Torch.Tensor &lt;==&gt; NumPy.ndarray</span></span><br><span class="line">ndarray = tensor.cpu().numpy()                      <span class="comment"># torch.Tensor -&gt; np.ndarray.</span></span><br><span class="line">tensor = torch.from_numpy(ndarray).<span class="built_in">float</span>()          <span class="comment"># np.ndarray -&gt; torch.Tensor.</span></span><br><span class="line"><span class="comment"># If ndarray has negative stride:</span></span><br><span class="line"><span class="comment"># This means that your numpy array has undergone such operation: image = image[..., ::-1]</span></span><br><span class="line"><span class="comment"># User Case: </span></span><br><span class="line"><span class="comment"># If you don’t want to flip the image, if for example you have already trained a network with un-flipped images, then you can save and load the image before passing it for inference.</span></span><br><span class="line"><span class="comment"># Solution:</span></span><br><span class="line">tensor = torch.from_numpy(ndarray.copy()).<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape</span></span><br><span class="line">tensor = torch.reshape(tensor, shape)</span><br><span class="line"><span class="comment"># Shuffle the first dimension</span></span><br><span class="line">tensor = tensor[torch.randperm(tensor.size(<span class="number">0</span>))]</span><br><span class="line"><span class="comment"># tensor [::-1]: Assume tensor has shape N*D*H*W.</span></span><br><span class="line">tensor = tensor[:, :, :, torch.arange(tensor.size(<span class="number">3</span>) - <span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>).long()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Replication Operation       |  New/Shared memory | Still in computation graph |</span></span><br><span class="line">tensor.clone()              <span class="comment"># |        New         |          Yes               |</span></span><br><span class="line">tensor.detach()             <span class="comment"># |      Shared        |          No                |</span></span><br><span class="line">tensor.detach.clone()()     <span class="comment"># |        New         |          No                |</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Splicing</span></span><br><span class="line">tensor = torch.cat(list_of_tensors, dim=<span class="number">0</span>)          <span class="comment"># Stitching along the given dimension: 3 * 10×5 -&gt; 30×5</span></span><br><span class="line">tensor = torch.stack(list_of_tensors, dim=<span class="number">0</span>)        <span class="comment"># Add one more dimension: 3 * 10×5 -&gt; 3×10×5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># One-hot Code</span></span><br><span class="line">N = tensor.size(<span class="number">0</span>)</span><br><span class="line">one_hot = torch.zeros(N, num_classes).long()</span><br><span class="line">one_hot.scatter_(dim=<span class="number">1</span>, index=torch.unsqueeze(tensor, dim=<span class="number">1</span>), src=torch.ones(N, num_classes).long())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Zero Elements</span></span><br><span class="line">torch.nonzero(tensor)                               <span class="comment"># Index of non-zero elements</span></span><br><span class="line">torch.nonzero(tensor == <span class="number">0</span>)                          <span class="comment"># Index of zero elements</span></span><br><span class="line">torch.nonzero(tensor).size(<span class="number">0</span>)                       <span class="comment"># Number of non-zero elements</span></span><br><span class="line">torch.nonzero(tensor == <span class="number">0</span>).size(<span class="number">0</span>)                  <span class="comment"># Number of zero elements</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Equal Judgement</span></span><br><span class="line">torch.allclose(tensor1, tensor2)                    <span class="comment"># float tensor</span></span><br><span class="line">torch.equal(tensor1, tensor2)                       <span class="comment"># int tensor</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Expand</span></span><br><span class="line">torch.reshape(tensor, (<span class="number">64</span>, <span class="number">512</span>, <span class="number">1</span>, <span class="number">1</span>)).expand(<span class="number">64</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>) <span class="comment"># Expand tensor of shape 64*512 to shape 64*512*7*7.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Matrix Multiplication</span></span><br><span class="line">result = torch.mm(tensor1, tensor2)                 <span class="comment"># (m*n) * (n*p) -&gt; (m*p)</span></span><br><span class="line">result = torch.bmm(tensor1, tensor2)                <span class="comment"># Batch matrix multiplication: (b*m*n) * (b*n*p) -&gt; (b*m*p)</span></span><br><span class="line">result = tensor1 * tensor2                          <span class="comment"># Element-wise multiplication</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Euclidean Distance</span></span><br><span class="line">dist = torch.sqrt(torch.<span class="built_in">sum</span>((X1[:,<span class="literal">None</span>,:] - X2) ** <span class="number">2</span>, dim=<span class="number">2</span>)) <span class="comment"># X1: m*d, X2: n*d.</span></span><br></pre></td></tr></table></figure>
<p><img src="https://pic2.zhimg.com/v2-35c1855d415cf6958566483e1c607693_1440w.jpg?source=172ae18b" alt=""></p>
<hr>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><strong>Official Resources</strong><ul>
<li><a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html"><strong>Paper: </strong>PyTorch: An Imperative Style, High-Performance Deep Learning Library</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/pytorch/examples"><strong>Github:</strong> PyTorch Examples</a></li>
<li><strong><a target="_blank" rel="noopener" href="https://discuss.pytorch.org/latest?order=views">PyTorch Forum</a></strong></li>
<li><strong><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/index.html">PyTorch Documentation</a></strong></li>
</ul>
</li>
<li><strong>Zhihu:</strong> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/59205847?">PyTorch Cookbook(Collection of commonly used code snippets)</a></li>
<li><strong>Github</strong><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/intermt/awesome-pytorch-chinese">awesome-pytorch-chinese</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/bharathgs/Awesome-pytorch-list">awesome-Pytorch-list</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/zergtant/pytorch-handbook">pytorch-handbook</a></li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      
        <div id="donation_div"></div>


<script src="/Blog/js/vdonate.js"></script>

<script>
var a = new Donate({
  title: '如果觉得我的文章对您有用，请随意打赏。您的支持将鼓励我继续创作!', // 可选参数，打赏标题
  btnText: 'Donate', // 可选参数，打赏按钮文字
  el: document.getElementById('donation_div'),
  wechatImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/WeChanQR.png',
  alipayImage: 'https://raw.githubusercontent.com/iTimeTraveler/iTimeTraveler.github.io/site/source/about/donate/images/AliPayQR.jpg'
});
</script>
      
      
      <div>
        <ul class="post-copyright">
          <li class="post-copyright-author">
          <strong>Post author:  </strong>Haojun(Vincent) Gao</a>
          </li>
          <li class="post-copyright-link">
          <strong>Post link:  </strong>
          <a href="/Blog/2021/01/17/The-Design-Principle-of-Pytorch-Architecture/" target="_blank" title="The Design Principle of PyTorch Architecture">http://vincentgaohj.github.io/Blog/2021/01/17/The-Design-Principle-of-Pytorch-Architecture/</a>
          </li>
          <li class="post-copyright-license">
            <strong>Copyright Notice:   </strong>
            All articles in this blog are licensed under <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">CC BY-NC-ND 4.0</a>
            unless stating additionally.
          </li>
         
        </ul>
<div>

      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/Deep-Learning/" rel="tag">Deep Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/Blog/tags/PyTorch/" rel="tag">PyTorch</a></li></ul>

      

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/Blog/2021/01/10/Build-Modern-Serverless-Applications-with-AWS-Amplify-and-AppSync/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Build Modern Serverless Applications with AWS Amplify and AppSync</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Design-principles"><span class="nav-number">1.</span> <span class="nav-text">Design principles</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Usability-Centric-Design"><span class="nav-number">2.</span> <span class="nav-text">Usability Centric Design</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Deep-learning-models-are-just-Python-programs"><span class="nav-number">2.1.</span> <span class="nav-text">Deep learning models are just Python programs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Interoperability-and-extensibility"><span class="nav-number">2.2.</span> <span class="nav-text">Interoperability and extensibility</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Automatic-differentiation"><span class="nav-number">2.3.</span> <span class="nav-text">Automatic differentiation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Common-Code-Snippets"><span class="nav-number">3.</span> <span class="nav-text">Common Code Snippets</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Configuration"><span class="nav-number">3.1.</span> <span class="nav-text">Configuration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Tensor"><span class="nav-number">3.2.</span> <span class="nav-text">Tensor</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2013 - 2021 Gao Haojun All Rights Reserved.</p>
	      
	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>



<!-- 2017.6.11，masikkk新增，加载本地Google Prettify 代码高亮js代码 -->

<!--
<script src="/Blog/js/prettify.js"></script>
-->

<!-- 2017.6.11，masikkk新增，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(window).load(function(){})是在页面所有元素(包括所有css,js,图片,Flash等)加载完毕后执行
<script type="text/javascript">
$(window).load(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->
<!-- 2017.7.1，masikkk添加，用于Google Prettify 代码高亮，给pre标签添加class "prettyprint linenums"，有行号 -->
<!-- jQuery的$(document).ready(function(){})是当页面的标准DOM元素被解析成DOM树后就执行 -->

<!--
<script type="text/javascript">
$(document).ready(function(){
 $('pre').addClass('prettyprint linenums');
 $('code').addClass('prettyprint');
 prettyPrint();
 })
</script>
-->

<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>



    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/Blog/" class="mobile-nav-link">Home</a>
  
    <a href="/Blog/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/Blog/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/Blog/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/Blog/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  
<link rel="stylesheet" href="/Blog/fancybox/jquery.fancybox.css">

  
<script src="/Blog/fancybox/jquery.fancybox.pack.js"></script>




<script src="/Blog/js/scripts.js"></script>





  
<script src="/Blog/js/dialog.js"></script>









	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
	</script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            Gao Haojun
          </div>
          <div class="panel-body">
            Copyright © 2021 Haojun(Vincent) Gao All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</body>
</html>